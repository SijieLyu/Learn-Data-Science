{"cells":[{"cell_type":"markdown","source":["# Lesson 13 - Example: Word Count"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed2aab79-ba11-42cb-b034-3493fcfc36e3"}}},{"cell_type":"markdown","source":["### Introduction\n\nIn this lesson, we will work with text data. Our goal will be to determine the most frequently used words in the H. G. Wells novel, \"The War of the Worlds\"."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0ac6b736-15be-4cc5-a557-10e107b2b829"}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b776377c-c2c7-42c5-80fc-aa55bedce0dc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["spark = SparkSession.builder.getOrCreate()\nsc = spark.sparkContext"],"metadata":{"scrolled":true,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d1eade1d-3418-4329-b554-80dd4be494a4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Read Data\n\nWe will read the data in from a text file and will count the lines in the resulting RDD."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dcc94c9e-5d70-4909-86f8-befb1e53f601"}}},{"cell_type":"code","source":["lines_rdd = sc.textFile('/FileStore/tables/war_of_the_worlds.txt')\nprint(lines_rdd.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7f06a2e2-12f9-4211-9b1a-e554a0540c6b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["To get a sense as to the contents of the file, we will print out the first 20 elements of the RDD."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"18d2be51-6fb8-48e9-88d8-7c9b349148c3"}}},{"cell_type":"code","source":["for line in lines_rdd.take(20):\n    print(line)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e5d55f5-8f14-4423-8d92-f0704dcc386b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Processing the Data\n\nOur goal to create an RDD whose elements are individual words within the novel. As we are doing this, we will perform a small amount of preprocessing. In particular, we will convert all of the words to lower case and will strip out any punctuation. We will start with an example to illustrate how the process of stripping out punctuation is performed."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"901488d9-54a6-41c0-9864-244399513892"}}},{"cell_type":"code","source":["from string import punctuation\n\nprint(punctuation)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc5fc589-66b1-4521-a51c-f4e23d63b98f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["test_string = '\"Hello, Word!\"'\nprint(test_string)\nprint(test_string.strip(punctuation))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4845b04-c55b-48a6-acd6-42c5024a5e75"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["In the cell below, we process each line of the RDD by performing the following steps, in order:\n\n1. We use `flatMap()` to tokenize the data, splitting on the space character.\n2. We use `flatMap()` to tokenize the data, splitting on the hyphen character.\n3. We use `map()` to convert each string to lower case.\n4. We use `map()` to strip punctuation marks from the end of the strings. \n5. We use `map()` to remove single-quotes (apostrophes).\n6. We use `filter()` to remove empty strings created in the steps above. \n\nWe then count the number of words in the resulting RDD, as well as the number of distinct words."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c99098ae-fd2c-48f6-bf76-e20ee90d0102"}}},{"cell_type":"code","source":["words_rdd = (\n    lines_rdd\n    .flatMap(lambda x : x.split(' '))      # Split o spaces\n    .flatMap(lambda x : x.split('-'))      # Split on hyphens\n    .map(lambda x : x.lower())             # Convert to lower case\n    .map(lambda x : x.strip(punctuation))  # Strip punctuation\n    .map(lambda x : x.replace(\"'\", ''))    # Remove apostrophes\n    .filter(lambda x : x != '')            # Remove empty strings\n)\n\nwords_rdd.persist()\n\nprint('Total number of words:   ', words_rdd.count())\nprint('Number of distinct words:', words_rdd.distinct().count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d06fc23-cda9-4a14-a149-d9c525faae3f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Calculating Word Frequencies\n\nWe will determine the number of times each of the unique words appears within the novel. We will perform this task as follows:\n\n1. We use `map()` to create a pair RDD containing elements of the form `(word, 1)`.\n2. We use `reduceByKey()` to group the pair RDDs by `word` and then sum the 1s to produce word counts. \n3. We use `sortBy()` to sort the RDD by word frequency, in descending order.\n\nTo reassure us that our approach was correct, we print the number of elements in the resulting RDD to confirm that it is the same as the number of distinct words in `words_rdd`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8a615ff4-4c5f-47c2-859f-d2bda98782fc"}}},{"cell_type":"code","source":["word_freq = (\n    words_rdd\n    .map(lambda x : (x, 1))\n    .reduceByKey(lambda x, y : x + y)\n    .sortBy(lambda x : x[1], ascending=False)\n)\n\nprint(word_freq.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ecf9d474-fb3c-4876-8b44-5f558ea2ae48"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["We will determine the 20 most commonly-occurring words in the novel."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c5f1a14-058e-48f3-ad58-3aacc3a500c5"}}},{"cell_type":"code","source":["for row in word_freq.take(20):\n    print(f'{row[0]:<12}{row[1]:>4}')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aa6719e9-b799-4063-bb2f-8c78312d4863"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Removing Stop Words\n\n%md These results are not very interesting. The most frequently appearing words are, unsuprisingly, \"the\", \"and\", \"of\", \"a\", and \"i\". Commonly occuring, low information words such as these are often called **stop words**. A typical task when performing a text-based analysis is to remove any instances of stop words. There is no commonly accepted definition of what is and what is not a stop word, and the definition used could vary by task. \n\nA document containing a list of stop words that we will use in this example has been provided at the following path: `/Filestore/tables/stopwords.txt`. The document contains one word per line. We will load the contents of this file into an RDD, and will then collect it into a list."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"59826e43-a45e-4f03-8314-248537a2ad5f"}}},{"cell_type":"code","source":["stopwords_rdd = sc.textFile('/FileStore/tables/stopwords.txt')\nstopwords = stopwords_rdd.collect()\n\nprint(len(stopwords))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eafd3b58-2159-438c-8ccf-10ea3eb92a92"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["We will now view the first 20 stop words contained in our list."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f38a937a-a277-49b1-bacd-9bbb3bded078"}}},{"cell_type":"code","source":["print(stopwords[:20])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"310d5297-fd53-465d-9c33-f0cb339f7614"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["We will conclude by reconstructing our word frequency RDD, but with stop words filtered out."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a6a2c475-31ea-4e0f-a777-422902ceb6ed"}}},{"cell_type":"code","source":["word_freq_ns = (\n    words_rdd\n    .filter(lambda x : x not in stopwords)\n    .map(lambda x : (x, 1))\n    .reduceByKey(lambda x, y : x + y)\n    .sortBy(lambda x : x[1], ascending=False)\n)\n\nprint(word_freq_ns.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e86fcb3-5d77-49b2-8a58-9716a0f9160b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["for row in word_freq_ns.take(20):\n    print(f'{row[0]:<12}{row[1]:>4}')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d6013f14-b247-4365-9fe3-a6c43e97ea3b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.1","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"13 - Example: Word Count","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2377394210003636}},"nbformat":4,"nbformat_minor":0}
