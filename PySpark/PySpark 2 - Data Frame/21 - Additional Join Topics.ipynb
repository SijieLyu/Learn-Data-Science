{"cells":[{"cell_type":"markdown","source":["# Lesson 21 - Additional Join Topics"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1eb704e2-67dc-4f67-8d14-4c7dcbe26df1"}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.getOrCreate()\nsc = spark.sparkContext"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5958223-93b9-4553-b4af-744d07e1b184"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Joining on Two Columns \n\nIt is possible to join two DataFrames using two or more key columns. In such a situation, two rows from different DataFrames are considered to be key-matched if and only if they share the same value in each of the key columns. To illustrate this concept, we will create two DataFrames named `LDF` and `RDF`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eef4b748-6f2b-499b-b9e6-291ef1cdcfde"}}},{"cell_type":"code","source":["LDF = spark.createDataFrame(\n    data = [['A', 1, 10], ['A', 2, 20], ['B', 2, 30]],\n    schema = 'c1 STRING, c2 INTEGER, c3 INTEGER'\n)\n\nRDF = spark.createDataFrame(\n    data = [['A', 1, 40], ['A', 1, 50], ['B', 1, 60], ['B', 2, 70]],                          \n    schema = 'c1 STRING, c2 INTEGER, c4 INTEGER'\n)\n\nLDF.show()\nRDF.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"683ec01e-285d-41ac-96ca-e23ccb2a1646"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["LDF.join(other=RDF, on=['c1','c2'], how='inner').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e64d35f-6b71-45aa-8988-ecae93e57df6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["For convenience, the contents of `LDF`, `RDF`, and the inner join are all provided below. \n    \n    LDF              RDF              Inner Join\n    +---+---+---+    +---+---+---+    +---+---+---+---+\n    | c1| c2| c3|    | c1| c2| c4|    | c1| c2| c3| c4|\n    +---+---+---+    +---+---+---+    +---+---+---+---+\n    |  A|  1| 10|    |  A|  1| 40|    |  A|  1| 10| 40|\n    |  A|  2| 20|    |  A|  1| 50|    |  A|  1| 10| 50|\n    |  B|  2| 30|    |  B|  1| 60|    |  B|  2| 30| 70|\n    +---+---+---+    |  B|  2| 70|    +---+---+---+---+\n                     +---+---+---+"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5cc44bc-4c29-44ee-b3b9-1d3e652211ee"}}},{"cell_type":"markdown","source":["## Joining on Differently-Named Key Columns\n\nThere are occasions when we need to join two DataFrames using key columns that have different names in the two DataFrames being joined. A fairly straight-forward way to address this issue is to simply rename the key column in one of the two DataFrames. If, for whatever reason, that is undesirable, then we can still perform the join by passing to the on parameter an expression performing an equality comparison between the two key columns."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"17fb06a0-7c69-4ca2-b11b-782ae61f48d0"}}},{"cell_type":"code","source":["X = spark.createDataFrame(\n  data = [[1, 'A'], [2, 'B'], [2, 'C'], [3, 'D']],\n  schema = 'c1 INT, c2 STRING'\n)\n\nY = spark.createDataFrame(\n  data = [[1, 'E'], [1, 'F'], [3, 'G'], [3, 'H']],\n  schema = 'd1 INT, d2 STRING'\n)\n\nX.show()\nY.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9225843c-2214-40b1-8698-a3d45bb611db"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["X.join(other=Y, on=(X.c1 == Y.d1), how='inner').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"295035ba-f71e-4264-b23d-eb3ca1008ae5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["For convenience, the contents of `X`, `Y`, and the inner join are all provided below. \n    \n    X            Y            Inner Join\n    +---+---+    +---+---+    +---+---+---+---+\n    | c1| c2|    | d1| d2|    | c1| c2| d1| d2|\n    +---+---+    +---+---+    +---+---+---+---+\n    |  1|  A|    |  1|  E|    |  1|  A|  1|  E|\n    |  2|  B|    |  1|  F|    |  1|  A|  1|  F|\n    |  2|  C|    |  3|  G|    |  3|  D|  3|  G|\n    |  3|  D|    |  3|  H|    |  3|  D|  3|  H|\n    +---+---+    +---+---+    +---+---+---+---+"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04c90734-1656-4b62-8ce2-65ef0ae85076"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"21 - Additional Join Topics","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2377394210003433}},"nbformat":4,"nbformat_minor":0}
