{"cells":[{"cell_type":"markdown","source":["# Lesson 10 - Lazy Evaluation and Persistence"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed2aab79-ba11-42cb-b034-3493fcfc36e3"}}},{"cell_type":"markdown","source":["## Prepare Environment\n\nWe will begin the lesson by importing some packages and creating `SparkSession` and `SparklContext` objects."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7faec295-36f3-422b-b53b-53da5a673299"}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.mllib.random import RandomRDDs\n\nimport numpy as np\nimport time\n\nspark = SparkSession.builder.getOrCreate()\nsc = spark.sparkContext"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7025764-3e28-4a84-849f-92cb215c4099"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Lazy Evaluation\n\nThe classification of RDD methods as transformations and actions provides more than a conceptual organization of these methods. Spark treats transformations and actions in different ways, and it is important to understand this difference.\n\nWhen a transformation is called on an RDD, Spark will not immediately perform the requested calculation. Instead, it will add the transformation to a queue of transformations. A queued transformation will not be performed until an action is called that depends on the output of that transformation. This evaluation strategy is referred to as **lazy evaluation**. \n\nLazy evaluation allows Spark to postpone expensive transformations until absolutely necessary. It also allows Spark to perform some behind the scenes optimization on the queued transformations when an action is called."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0ac6b736-15be-4cc5-a557-10e107b2b829"}}},{"cell_type":"markdown","source":["We will now consider a few examples to illustrate the effects of lazy evaluation. Note that these examples are not intended to be practical examples. Their only purpose is to provide you with a deeper understanding of how lazy evaluation works. \n\nIn the next cell, we will construct an RDD containing 50 million values selected at random from the interval `[0,1]`. We will use this RDD in the examples in this section."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eaa8b61f-c670-41e3-811b-23291af0f21c"}}},{"cell_type":"code","source":["rand_rdd = RandomRDDs.uniformRDD(sc, size=50000000, numPartitions=8, seed=1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57b605e7-9796-4783-bccf-e6e9e8267931"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["#### Example 1\n\nIn our first example, we will use `map()` to perform a simple transformation of our RDD, adding 1 to each element. We will then use the `sum()`  action to sum to elements of the resulting RDD. We will measure the time required to perform each of these two RDD methods."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"10486274-5934-4194-b4f3-9bec9f081137"}}},{"cell_type":"code","source":["t1 = time.time()\nnew_rdd = rand_rdd.map(lambda x : x+1)   # Add 1 to each element of rand_rdd\nt2 = time.time()\ntotal = new_rdd.sum()                    # Sum elements of new_rdd\nt3 = time.time()\n\nprint('Map Time:', t2 - t1)\nprint('Sum Time:', t3 - t2)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87f8f43b-0012-40c1-8b67-b9f3cd4c19d6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Map Time: 0.0007023811340332031\nSum Time: 8.857218980789185\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Map Time: 0.0007023811340332031\nSum Time: 8.857218980789185\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["Notice that the `map()` transformation took almost no time at all to run, while the `sum()` action required around 5 seconds to execute. We are seeing lazy evaluation in action (or inaction, as the case may be). \n\nSince `map()` is a transformation, no calculations are performed when this method is called. Instead, the transformation is placed into a queue until action is called that requires the results of the `map()`. As a matter of fact, the values in `rand_rdd` don't actually even exist until an action is called that requires these values to be generated. \n\nNo calculation are performed until the `sum()` action is called. At that point, the elements of the RDD are generated, the `map()` transformation is applied, and then the values are totaled, with the final sum being returned to the driver."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"143acd48-bf82-46ca-a036-de49f0cd71cc"}}},{"cell_type":"markdown","source":["#### Example 2\n\nIn the next example, we will add a second `map()` transformation prior to calling the `sum()` action. We will again measure the time required by each method."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dce81713-4bf9-4141-80a4-80c946ecb287"}}},{"cell_type":"code","source":["t1 = time.time()\ntemp_rdd_1 = rand_rdd.map(lambda x : x+1)     # Add 1 to each element of rand_rdd\nt2 = time.time()\ntemp_rdd_2 = temp_rdd_1.map(lambda x : x**2)  # Square each value in the new RDD\nt3 = time.time()\ntemp_rdd_2.sum()                              # Sum elements in the final RDD\nt4 = time.time()\n\n\nprint('Map 1 Time:', t2 - t1)\nprint('Map 2 Time:', t3 - t2)\nprint('Sum Time:  ', t4 - t3)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e99b57f-0771-421f-990b-56d10696adc7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Map 1 Time: 0.0003724098205566406\nMap 2 Time: 7.891654968261719e-05\nSum Time:   14.63025689125061\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Map 1 Time: 0.0003724098205566406\nMap 2 Time: 7.891654968261719e-05\nSum Time:   14.63025689125061\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["Notice that the time required by the either of the `map()` transformations was again insubstantial. That is because neither transformation is actually performed until `sum()` is called. \n\nThe `sum()` method did take longer to execute in this example than in the previous one. That is because there are two `map()` transformations processed in this example rather than the single one in the previous example. \n\nHowever, consider what happens if you replace `temp_rdd_2.sum()` with `temp_rdd_1.sum()` in the code cell above. Try this now. You should notice that the amount of time required by the `sum()` action in this case is similar to that in the first example. This is because the sum in this modified version of the code is not dependent on the results of the second transformation. As a result, that transformation is not triggered by calling the `sum()` action. Only the first transformation is actually performed."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"78f11828-66d5-4962-ab9e-158365a7ff61"}}},{"cell_type":"markdown","source":["## Persistence\n\nBy default, Spark will calculate the contents of an RDD only when required to do so by an action. While an action is being processed, the values of an RDD will be stored in the memory of the nodes in the cluster, which each node storing their own partitions of the RDD. However, the RDD values will be removed from memory as soon as the action has completed. This can help to avoid tying up valuable resources with RDDs that are no longer needed, but it also has a downside. Any time an RDD is needed for an action, it will have to be recalcuated from the entire chain of transformations that defined that particular RDD. If will expect to be performing multiple calculations with an RDD, it can be terribly inefficient to have to recalculate the RDD from scratch every time. \n\nFortunately, Spark provides a `.persist()` method that allows us to cache an RDD to memory for reuse. If we call this method on an RDD, then the next time the contents of that RDD are computed, they will be preserved in memory on the nodes in the network. This will speed up future calculations involving this RDD, but will also required additional use of limited memory resources. If we decide to later free up these memory resources, we can do so by calling the `.unpersist()` method of the RDD."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"919f441f-9d0b-437d-9d7e-f679ef3878c0"}}},{"cell_type":"markdown","source":["### Example 3\n\nIn the cell below, we will create an RDD using `map()`, and will then call `count()` on this RDD twice. As in the previous examples, we will calculate the time required by each method call."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d2f71d6-38ba-47c4-b5b1-6fcd8dcd53c2"}}},{"cell_type":"code","source":["t1 = time.time()\nmy_rdd = rand_rdd.map(lambda x : x**2)   # Square each element of rand_rdd\nt2 = time.time()\nmy_rdd.count()                           # Count elements in my_rdd\nt3 = time.time()\nmy_rdd.count()                           # Count elements in my_rdd\nt4 = time.time()\n\nprint('Map Time:     ', t2 - t1)\nprint('Count 1 Time:', t3 - t2)\nprint('Count 2 Time:', t4 - t3)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e1a83afa-ae97-452e-97a0-0ce2b72b764f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Map Time:      0.00039887428283691406\nCount 1 Time: 9.601279020309448\nCount 2 Time: 9.69595980644226\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Map Time:      0.00039887428283691406\nCount 1 Time: 9.601279020309448\nCount 2 Time: 9.69595980644226\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["Notice that each `count()` action in the cell above took roughly the same amount of time to run. Much of the required to perform this action is actually spent performing the queued `map()` transformation. This transformation will get performed from scratch both times `count()` is called. \n\nTo see this, we will modify the example above by persisting `my_rdd` after calling `map()`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f9cf4a03-98db-4e7e-a596-e6bb34241d2d"}}},{"cell_type":"code","source":["t1 = time.time()\nmy_rdd = rand_rdd.map(lambda x : x**2)   # Square each element of rand_rdd\nt2 = time.time() \nmy_rdd.persist()                         # Persist my_rdd\nt3 = time.time()\nmy_rdd.count()                           # Count elements in my_rdd\nt4 = time.time()\nmy_rdd.count()                           # Count elements in my_rdd\nt5 = time.time()\n\n\nprint('Map Time:    ', t2 - t1)\nprint('Persist Time:', t3 - t2)\nprint('Count 1 Time:', t4 - t3)\nprint('Count 2 Time:', t5 - t4)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3635f991-1b0c-43db-bbbc-8cd467474fb6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Map Time:     0.00040721893310546875\nPersist Time: 0.02400350570678711\nCount 1 Time: 13.139666318893433\nCount 2 Time: 2.1303367614746094\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Map Time:     0.00040721893310546875\nPersist Time: 0.02400350570678711\nCount 1 Time: 13.139666318893433\nCount 2 Time: 2.1303367614746094\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["Notice that the second `count()` action takes significantly less time to run in this version of the example. The `map()` transformation defining `my_rdd` is performed when the first `count()` is called, but it is then stored in memory. As a result, the second call to `count()` does not need to recalculate `my_rdd` and needs only to count the elements in it."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"998d7916-51c1-4713-8068-f2de839afd4f"}}},{"cell_type":"markdown","source":["### Example 4\n\nIn the next example, we will work with an RDD that is expensive to create. To simulate an expensive operation for creating an RDD, we will define a function that performs several pointless calculations, but then returns the square root of the input."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bde31624-2a83-460d-aa6c-b3574f33b4ef"}}},{"cell_type":"markdown","source":["In the cell below, we define `sqrt_rdd` using `map()` and `expensive_fn()`. We define `filtered_rdd` based on `sqrt_rdd`, on which we call `sum()` and `count()`. When either of these final two actions are called, both `sqrt_rdd` and `filtered_rdd` are recalculated from scratch."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b712a6a-20cf-41cf-9abd-38b54588d5ea"}}},{"cell_type":"code","source":["t1 = time.time()\nsqrt_rdd = rand_rdd.map(lambda x : x ** 0.5)          # Take the square root of each RDD element\nt2 = time.time()\nfiltered_rdd = sqrt_rdd.filter(lambda x : x < 0.1)    # Filter out some elements of the RDD\nt3 = time.time()\nn = filtered_rdd.count()                              # Count elements in filtered RDD\nt4 = time.time()\ntotal = filtered_rdd.sum()                            # Sum elements in filtered RDD\nt5 = time.time()\n\nprint('Map Time:   ', t2 - t1)\nprint('Filter Time:', t3 - t2)\nprint('Count Time: ', t4 - t3)\nprint('Sum Time:   ', t5 - t4)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"63ef6201-93ad-4332-b78e-1a7332fb92ea"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Map Time:    0.00040340423583984375\nFilter Time: 8.940696716308594e-05\nCount Time:  14.926460266113281\nSum Time:    15.250807285308838\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Map Time:    0.00040340423583984375\nFilter Time: 8.940696716308594e-05\nCount Time:  14.926460266113281\nSum Time:    15.250807285308838\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["In the cell below, we call `persist()` on `filtered_rdd`. Notice that the `count()` still takes a long time to calculate (since neither `sqrt_rdd` or `filtered_rdd` are calculated until this step). However, the `sum()` is now performed much more quickly."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0b6d2e7-bd06-49a7-9b1f-0b8e34ab45c7"}}},{"cell_type":"code","source":["t1 = time.time()\nsqrt_rdd = rand_rdd.map(lambda x : x ** 0.5)                # Take the square root of each RDD element\nt2 = time.time()\nfiltered_rdd = sqrt_rdd.filter(lambda x : x < 0.1)          # Filter out some elements of the RDD\nt3 = time.time()\nfiltered_rdd.persist()                                      # Persist filtered RDD\nt4 = time.time()\nfiltered_rdd.count()                                        # Count elements in filtered RDD\nt5 = time.time()\nfiltered_rdd.sum()                                          # Sum elements in filtered RDD\nt6 = time.time()\n\nprint('Map Time:    ', t2 - t1)\nprint('Filter Time: ', t3 - t2)\nprint('Persist Time:', t4 - t3)\nprint('Count Time:  ', t5 - t4)\nprint('Sum Time:    ', t6 - t5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87bd9d2b-0f9a-48ae-9963-0cd25ea7ab1e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Map Time:     0.0003898143768310547\nFilter Time:  8.940696716308594e-05\nPersist Time: 0.019237756729125977\nCount Time:   14.871235132217407\nSum Time:     0.15732717514038086\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Map Time:     0.0003898143768310547\nFilter Time:  8.940696716308594e-05\nPersist Time: 0.019237756729125977\nCount Time:   14.871235132217407\nSum Time:     0.15732717514038086\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["filtered_rdd.unpersist()\n# to free up the memory"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4e7d444-43b1-4b42-ae68-66c409679613"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[10]: PythonRDD[76] at RDD at PythonRDD.scala:58</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[10]: PythonRDD[76] at RDD at PythonRDD.scala:58</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"13012782-02e7-4e1c-b3a1-4cf271ede1dd"}},"outputs":[],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.1","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"10 - Lazy Evaluation and Persistence","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2377394210004322}},"nbformat":4,"nbformat_minor":0}
