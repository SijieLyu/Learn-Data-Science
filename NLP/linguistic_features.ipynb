{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Text Mining\n","# Linguistic Features\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["**Objectives**\n","\n","+ Work with PDF files using PyPDF2\n","+ Perform tokenization.\n","+ Do lemmatization.\n","+ Remove the stop words.\n","+ Perform Part of Speech Tagging.\n","+ Visualize the part of speech tags\n","+ Do Named Entity Recondition.\n","+ Visualize the name entity recognization\n","\n","\n","\n","When we perform text mining, we typically need to clean and preprocess the texts. Spacy provides common APIs to perform linguistic features\n","based on a Doc object. By the end of this week, I hope you'll understand the linguistic features. I will show you how to process PDF files using PyPDF2 library. Then we will cover the following list of text preprocessing steps: tokenization, lemmatization, part of speech tagging (POS), and named entity recognization (NER). Last but not least, we will learn how to visualize the POS tags and NERs. \n","\n","\n","**Readings**\n","\n","+ Working with PDF files in Python (https://www.geeksforgeeks.org/working-with-pdf-files-in-python/)\n","+ Tokenization (https://spacy.io/usage/linguistic-features#tokenization)\n","+ Lemmatization (https://spacy.io/usage/linguistic-features#lemmatization)\n","+ Part of Speech Tagging (https://spacy.io/usage/linguistic-features#pos-tagging)\n","+ Named Entity Recondition (https://spacy.io/usage/linguistic-features#named-entities)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","# Linguistic Features\n","\n","We have learned how to clean and impute the numerical values. We have lots of tools to handle numerical features. But it is much harder for us to clean and preprocess the raw text features. Different words may mean the same thing; for example, STL, The Gateway City, and The Lou mean Saint Louis. On the other handle, sometimes the same word could mean different things. For example, there is an apple on the Apple Ipad. The apple has different meanings. \n","\n","Spacy provides the linguistic features to help us clean and preprocess the raw texts. We will cover the following topics this week:\n","\n","+ Tokenization\n","+ Stemming\n","+ Lemmatization\n","+ Stop words\n","+ Part of speech Tagging\n","+ Named Entity Recognization\n"]},{"cell_type":"markdown","metadata":{},"source":["## Extract the Text from  PDF Files"]},{"cell_type":"markdown","metadata":{},"source":["Probably PDF is the most popular file format. These files can be accessed using a PC, Ipad, and smartphone on different operating systems such as Linux, macOS, and Windows. Therefore, we need a tool to handle PDF files using Python. There are many libraries to work with PDF files. We will use the PyPDF2 library (https://pypi.org/project/PyPDF2). It can perform the following tasks:\n","\n","+ extracting document information (title, author, …)\n","+ splitting documents page by page\n","+ merging documents page by page\n","+ cropping pages\n","+ merging multiple pages into a single page\n","+ encrypting and decrypting PDF files\n","\n","There are two methods to install PyPDF2.\n","\n","1. Install it with conda; we need to  run the following command: **conda install -c conda-forge pypdf2** in Anaconda Prompt.\n","2. Install it with Jupyter Notebook; we need to run **pip install PyPDF2** in a cell.\n","\n","Let's install it in the Jupyter Notebook."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# !pip install PyPDF2"]},{"cell_type":"markdown","metadata":{},"source":["Let's load a paper titled \"Dollar-cost averaging just means taking risk later\" by Vanguard, into memory."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" There are 20 pages in the file :/Volumes/External/DSCI/508_ML/NN/transfer learning w Python.pdf\n"]},{"name":"stderr","output_type":"stream","text":["PdfReadWarning: Superfluous whitespace found in object header b'49' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'50' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'51' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'52' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'53' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'55' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'58' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'59' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'60' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'61' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'62' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'63' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'64' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'65' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'66' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'67' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'68' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'71' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'72' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'73' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'74' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'76' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'79' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'80' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'81' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'82' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'83' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'84' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'85' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'86' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'87' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'88' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'89' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'90' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'93' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'94' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'95' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'96' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'97' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'98' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'99' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'100' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'103' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'104' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'107' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'108' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'109' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'110' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'111' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'112' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'113' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'114' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'115' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'116' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'119' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'120' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'121' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'122' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'123' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'124' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'125' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'126' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'129' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'130' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'131' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'133' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'136' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'137' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'138' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'139' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'140' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'142' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'145' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'146' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'149' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'152' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'153' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'154' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'155' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'156' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'157' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'158' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'159' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'162' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'163' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'164' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'165' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'167' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'170' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'171' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'172' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'173' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'174' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'175' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'176' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'177' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'180' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'181' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'182' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'183' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'184' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'185' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'186' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'187' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'188' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'191' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'192' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'193' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'194' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'195' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'196' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'197' b'0' [pdf.py:1665]\n","PdfReadWarning: Superfluous whitespace found in object header b'236' b'0' [pdf.py:1665]\n"]},{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","\n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n"," \n","\n","\n","\n","----------------------------------------------------------------------------------------------------\n","----------------------------------------------------------------------------------------------------\n","                   \n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["PdfReadWarning: Superfluous whitespace found in object header b'280' b'0' [pdf.py:1665]\n"]}],"source":["# Load the required library into memory\n","import PyPDF2\n","import re\n","\n","# Specify file\n","mypdf = '/Volumes/External/DSCI/508_ML/NN/transfer learning w Python.pdf'\n","\n","#Creating a pdf file object\n","pdfFile = open(mypdf, 'rb')\n","  \n","# Creating a pdf reader object\n","pdfFileReader = PyPDF2.PdfFileReader(pdfFile)\n","\n","# Get the number of pages in the pdf file\n","pageCount = pdfFileReader.numPages\n","# printing number of pages in pdf file\n","print(f' There are {pageCount} pages in the file :{mypdf}')\n","  \n","output = []    \n","for i in range(pageCount):\n","    # Get the i-th page contents from the pdf file\n","    pdfPage = pdfFileReader.getPage(i)\n","    # Extract text from each page and append it to the list\n","    output.append(pdfPage.extractText())\n","    \n","# Concatenate items in the list to a single string\n","alltexts = ' '.join(output)\n","\n","# Print out  the first 300 chars from the texts\n","print(\"----\" * 25)\n","print(alltexts[:300])\n","print(\"----\" * 25)  \n","\n","# Remove \\n from the texts\n","alltexts = re.sub('\\n', '', alltexts)\n","# Remove punctuation from the texts\n","alltexts = re.sub(r'[^\\w\\s]','',alltexts)\n","\n","# Print out  the first 300 chars from the texts\n","print(\"----\" * 25)\n","print(alltexts[:300])\n","print(\"----\" * 25)  \n","# closing the pdf file object\n","pdfFile.close()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Tokenization\n","\n","We notice that all the texts are stored in a single string object of alltexts. We want to split the entire pdf document into smaller segments, such as individual words called tokens.\n","\n","To process texts in Spacy; we first need to generate a **Doc** object using nlp function."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["UserWarning: [W095] Model 'en_core_web_sm' (3.0.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.1.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate [util.py:730]\n"]},{"name":"stdout","output_type":"stream","text":["Token text =                    ; Is the token lowercase? False; Does the token consit of digits? False \n"]}],"source":["import spacy\n","# Load the model\n","nlp = spacy.load(\"en_core_web_sm\")\n","# Process the texts\n","doc = nlp(alltexts)\n","# Print out the first 50 tokens\n","for token in doc[:50]:\n","    print(f'Token text = {token.text}; Is the token lowercase? {token.is_lower}; Does the token consit of digits? {token.is_digit} ')"]},{"cell_type":"markdown","metadata":{},"source":["Spacy token supports many attributes such as doc, sent, text, etc. Please see the official help documents for details. (https://spacy.io/api/token#attributes)"]},{"cell_type":"markdown","metadata":{},"source":["## Stemming and Lemmatization\n","\n","The documents use different forms of a word/token such as go, went, going, etc. When we handle texts, there are typically lots of tokens. We like to reduce the derived words to their word stem, such as go for go, went, and going. According to Wikipedia (https://en.wikipedia.org/wiki/Stemming), \"The stem need not be identical to the morphological root of the word; it is usually sufficient that related words map to the same stem, even if this stem is not in itself a valid root.\" Spacy doesn't provide any function for stemming at all.\n","\n","Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma .\n","\n","According to Wikipedia:\n","\n","\" Lemmatization is closely related to stemming. The difference is that a stemmer operates on a single word without knowledge of the context, and therefore cannot discriminate between words that have different meanings depending on the part of speech. However, stemmers are typically easier to implement and run faster. The reduced \"accuracy\" may not matter for some applications. In fact, when used within information retrieval systems, stemming improves query recall accuracy, or true positive rate, when compared to lemmatization. Nonetheless, stemming reduces precision, or the proportion of positively-labeled instances that are actually positive, for such systems.\n","\n","For instance:\n","\n","+ The word \"better\" has \"good\" as its lemma. This link is missed by stemming, as it requires a dictionary look-up.\n","+ The word \"walk\" is the base form for the word \"walking\", and hence this is matched in both stemming and lemmatization.\n","+ The word \"meeting\" can be either the base form of a noun or a form of a verb (\"to meet\") depending on the context, e.g., \"in our last meeting\" or \"We are meeting again tomorrow\". Unlike stemming, lemmatization attempts to select the correct lemma depending on the context.\"\n","\n","Source: https://en.wikipedia.org/wiki/Lemmatisation"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Token text =                    ; The lemma =                    \n"]}],"source":["import spacy\n","# Load the model\n","nlp = spacy.load(\"en_core_web_sm\")\n","# Process the texts\n","doc = nlp(alltexts)\n","# Print out the first 50 tokens\n","for token in doc[:50]:\n","    print(f'Token text = {token.text}; The lemma ={token.lemma_} ')"]},{"cell_type":"markdown","metadata":{},"source":["## Stop Words\n","\n","When we speak English, the sentence may contain different words. For example, \"It is a beautiful day!\". However, there are five words in the previous sentence. There are only two keywords of \"beautiful day\". The other three words are the most common words in English. They contain little info. After we remove the stop words, we reduce the size of the tokens/words. It may help improve the performance of text mining.\n","\n","### Remove Stopwords\n","We can remove stopwords while performing the following tasks:\n","\n","+ Text Classification\n","    + Spam Filtering\n","    + Language Classification\n","    + Genre Classification\n","+ Caption Generation\n","+ Auto-Tag Generation\n"," \n","\n","### Avoid Stopword Removal\n","+ Machine Translation\n","+ Language Modeling\n","+ Text Summarization\n","+ Question-Answering problems\n","\n","Source: https://www.analyticsvidhya.com/blog/2019/08/how-to-remove-stopwords-text-normalization-nltk-spacy-gensim-python/\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Let's look at Spacy's default stop words"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'now', 'why', 'namely', 'ourselves', 'show', 'whenever', 'due', 'them', 'those', 'take', 'give', 'only', 'well', 'least', 'anywhere', 'else', 'much', \"'ve\", 'across', 'perhaps', \"n't\", 'sixty', 'seem', 'anyway', 'us', '’re', 'own', 'been', 'along', 'since', 'somewhere', 'who', 'whole', 'twelve', 'were', 'from', 'anyhow', 'side', 'full', 'my', 'any', 'thereby', 'ours', 'eleven', 'thereafter', 'just', 'whom', 'again', 'hereby', 'be', 'nine', 'being', 'am', 'back', 'often', 'amongst', 'can', 'against', 'afterwards', 'n‘t', \"'d\", 'top', 'your', 'thereupon', 'together', 'what', '‘ll', 'anything', 'even', 'amount', 'third', 'throughout', 'unless', 'some', 'after', 'whatever', 'almost', 'because', 'bottom', 'how', 'still', 'in', 'except', \"'m\", 'whereafter', 'they', 'seemed', 'less', 'through', 'would', 'either', 'such', 'could', 'this', 'wherever', 'yours', 'me', '‘d', 'fifteen', 'seems', 'three', 'may', 'ever', 'no', 'everything', 'few', 'name', 'fifty', 'whose', 'itself', 'down', 'most', 'with', 'between', 'when', 'everyone', 'will', 'myself', 'up', 'thru', 'n’t', 'go', 'elsewhere', 'above', 'get', 'his', 'various', 'had', 'becomes', 'that', 'rather', 'herself', 'whether', 'via', 'beforehand', 'last', 'somehow', 'made', 'one', 'make', 'its', 'noone', 'there', 'is', 'something', 'during', 'we', 'at', '’s', 'never', 'behind', '’ve', 'however', 'not', 'off', '‘ve', 'whither', 'these', '’ll', 'part', 'meanwhile', 'her', 'done', 'below', 'indeed', 'otherwise', 'someone', 'i', 'next', 'but', 'per', 'and', 'further', 'should', 'or', 'then', 'seeming', 'onto', 'here', 'used', 'hereafter', \"'s\", 'therein', 'thence', 'regarding', 'of', 're', 'must', 'already', 'see', 'mine', 'our', 'into', 'the', 'hereupon', 'has', 'yourself', 'very', 'others', 'latterly', 'many', 'five', '‘m', 'hence', 'same', 'whereupon', 'always', '’d', 'enough', '’m', 'forty', 'everywhere', 'mostly', 'he', 'keep', 'quite', 'for', 'another', 'it', 'their', 'none', 'first', 'nowhere', 'which', 'by', 'herein', 'themselves', 'becoming', 'ca', 'more', 'towards', 'without', 'serious', 'a', 'therefore', 'also', 'four', \"'re\", 'sometime', 'beside', 'over', 'you', 'whereby', 'an', 'too', 'if', 'really', 'around', 'two', 'until', 'other', 'anyone', 'former', 'formerly', 'within', 'among', 'eight', 'does', 'put', 'as', 'twenty', 'she', 'though', 'have', 'while', 'whoever', 'yet', 'became', 'beyond', 'cannot', 'where', 'besides', 'moreover', 'neither', 'under', 'doing', 'yourselves', 'out', 'are', 'become', 'using', 'every', 'about', 'nevertheless', 'do', 'empty', 'thus', 'than', 'before', 'several', 'nor', 'ten', 'all', 'upon', 'latter', 'each', 'hundred', 'himself', 'him', '‘s', '‘re', 'on', 'say', 'call', \"'ll\", 'please', 'so', 'sometimes', 'nobody', 'did', 'once', 'nothing', 'move', 'whence', 'wherein', 'whereas', 'alone', 'hers', 'to', 'toward', 'might', 'six', 'was', 'both', 'although', 'front'}\n"]}],"source":["import spacy\n","\n","nlp = spacy.load('en_core_web_sm')\n","\n","spacy_stopwords = nlp.Defaults.stop_words\n","\n","print(spacy_stopwords)\n"]},{"cell_type":"markdown","metadata":{},"source":["We remove all the default stop words from the texts."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[                   ]\n"]}],"source":["\n","doc = nlp(alltexts)\n","\n","tokens_without_stopword= [token for token in doc if not token.text in spacy_stopwords]\n","\n","\n","print(tokens_without_stopword[:100])"]},{"cell_type":"markdown","metadata":{},"source":["We notice that Vanguard appears many times in this report. It doesn't contain lots of information.  We may decide to remove it by adding it to the stop word list. \n","Sometimes, we may need to remove several words from the default stop words and keep them in the texts for a specific task. For example, \"call\" and \"put\" are included in the spacy's default stop words. This report covers investment strategies. It may involve put and call options. Therefore, we decide to keep them in the texts, remove \"call\", and \"put\" from Spacy's default stop words. "]},{"cell_type":"markdown","metadata":{},"source":["### Add Customized Stop Words"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 326 stop words in Spacy\n","There are 328 stop words in Spacy\n"]}],"source":["print(f'There are {len(nlp.Defaults.stop_words)} stop words in Spacy')\n","# Specify the user defined stop words\n","customized_stop_words = ['Vanguard', 'market']\n","# Add the user specified stop words to the Spacy default stop words\n","for token in customized_stop_words:\n","    nlp.Defaults.stop_words.add(token)\n","\n","# Set the tag of the customized stop words as stop word \n","for token in customized_stop_words:\n","    nlp.vocab[token].is_stop = True\n","print(f'There are {len(nlp.Defaults.stop_words)} stop words in Spacy')"]},{"cell_type":"markdown","metadata":{},"source":["### Remove Stop Words"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 328 stop words in Spacy\n","There are 326 stop words in Spacy\n"]}],"source":["print(f'There are {len(nlp.Defaults.stop_words)} stop words in Spacy')\n","# Remove the the specified words from the default stop words of Spacy\n","remove_stop_words = ['call', 'put']\n","# Remove the user specified stop words from the Spacy default stop words\n","for token in remove_stop_words:\n","    nlp.Defaults.stop_words.remove(token)\n","\n","# Set the tag of the removed stop words as non-stop word \n","for token in remove_stop_words:\n","    nlp.vocab[token].is_stop = False\n","print(f'There are {len(nlp.Defaults.stop_words)} stop words in Spacy')"]},{"cell_type":"markdown","metadata":{},"source":["Let's clean the texts again based on the new defined stop words"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[                   ]\n"]}],"source":["doc = nlp(alltexts)\n","\n","# Get the new stop words\n","spacy_stopwords = nlp.Defaults.stop_words\n","\n","tokens_without_stopword= [token for token in doc if not token.text in spacy_stopwords]\n","\n","print(tokens_without_stopword[:250])"]},{"cell_type":"markdown","metadata":{},"source":["## Part of Speech Tagging \n","\n","A Part-Of-Speech Tagging (POS Tagging) can read text  and assigns parts of speech to each word (and other token), such as noun, verb, adjective, etc.\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                        SPACE _SP ROOT      False False\n"]}],"source":["import spacy\n","nlp = spacy.load(\"en_core_web_sm\")\n","# Process the texts\n","doc = nlp(alltexts)\n","\n","# Summarize the first 20 tokens\n","for token in doc[:20]:\n","    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n","            token.shape_, token.is_alpha, token.is_stop)"]},{"cell_type":"markdown","metadata":{},"source":["### Visualize the Dependency Parser\n","\n","It is well known that a graph is worth 1000 words. We can take advantage of the visualizer to show the dependency parser."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/html":["<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"91a778bf709e4a32a60693ee35e64492-0\" class=\"displacy\" width=\"750\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Text</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">mining</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">is</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">fun!</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n","</text>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-91a778bf709e4a32a60693ee35e64492-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-91a778bf709e4a32a60693ee35e64492-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-91a778bf709e4a32a60693ee35e64492-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-91a778bf709e4a32a60693ee35e64492-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M245,91.5 L237,79.5 253,79.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-91a778bf709e4a32a60693ee35e64492-0-2\" stroke-width=\"2px\" d=\"M420,89.5 C420,2.0 575.0,2.0 575.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-91a778bf709e4a32a60693ee35e64492-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M575.0,91.5 L583.0,79.5 567.0,79.5\" fill=\"currentColor\"/>\n","</g>\n","</svg></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["import spacy\n","from spacy import displacy\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","doc = nlp(\"Text mining is fun!\")\n","# Visualize it by seeting style to be \"dep\" and jupyter to be True\n","displacy.render(doc, style=\"dep\", jupyter = True)"]},{"cell_type":"markdown","metadata":{},"source":["## Named Entity Recondition (NER)\n","When we read the text, we naturally recognize named entities such as organizations, money, people, locations, etc. For example, in the news title\"Tesla buys $1.5 billion in bitcoin, plans to accept it as payment\", we can find the following named entities:\n","\n","+  **Tesla** is a company\n","+  **\\$1.5billion** is the money\n","\n","In information extraction, a named entity is a real-world object, such as persons, locations, organizations, products, etc., that can be denoted with a proper name. It can be abstract or have a physical existence. Examples of named entities include Barack Obama, New York City, Volkswagen Golf, or anything else that can be named. Named entities can simply be viewed as entity instances (e.g., New York City is an instance of a city).\n","\n","Source: https://en.wikipedia.org/wiki/Named_entity\n","\n","\n","Named entities are available as the ents property of a Doc object in Spacy."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Tesla 0 5 ORG\n","$1.5 billion 11 23 MONEY\n"]}],"source":["import spacy\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","doc = nlp(\"Tesla buys $1.5 billion in bitcoin, plans to accept it as payment\")\n","\n","for ent in doc.ents:\n","    print(ent.text, ent.start_char, ent.end_char, ent.label_)"]},{"cell_type":"markdown","metadata":{},"source":["## NER Labels\n","The NER labels are summarized as follows:\n","\n","<table>\n","<tr><th>TYPE</th><th>DESCRIPTION</th><th>EXAMPLE</th></tr>\n","<tr><td>`PERSON`</td><td>People, including fictional.</td><td>*Fred Flintstone*</td></tr>\n","<tr><td>`NORP`</td><td>Nationalities or religious or political groups.</td><td>*The Republican Party*</td></tr>\n","<tr><td>`FAC`</td><td>Buildings, airports, highways, bridges, etc.</td><td>*Logan International Airport, The Golden Gate*</td></tr>\n","<tr><td>`ORG`</td><td>Companies, agencies, institutions, etc.</td><td>*Microsoft, FBI, MIT*</td></tr>\n","<tr><td>`GPE`</td><td>Countries, cities, states.</td><td>*France, UAR, Chicago, Idaho*</td></tr>\n","<tr><td>`LOC`</td><td>Non-GPE locations, mountain ranges, bodies of water.</td><td>*Europe, Nile River, Midwest*</td></tr>\n","<tr><td>`PRODUCT`</td><td>Objects, vehicles, foods, etc. (Not services.)</td><td>*Formula 1*</td></tr>\n","<tr><td>`EVENT`</td><td>Named hurricanes, battles, wars, sports events, etc.</td><td>*Olympic Games*</td></tr>\n","<tr><td>`WORK_OF_ART`</td><td>Titles of books, songs, etc.</td><td>*The Mona Lisa*</td></tr>\n","<tr><td>`LAW`</td><td>Named documents made into laws.</td><td>*Roe v. Wade*</td></tr>\n","<tr><td>`LANGUAGE`</td><td>Any named language.</td><td>*English*</td></tr>\n","<tr><td>`DATE`</td><td>Absolute or relative dates or periods.</td><td>*20 July 1969*</td></tr>\n","<tr><td>`TIME`</td><td>Times smaller than a day.</td><td>*Four hours*</td></tr>\n","<tr><td>`PERCENT`</td><td>Percentage, including \"%\".</td><td>*Eighty percent*</td></tr>\n","<tr><td>`MONEY`</td><td>Monetary values, including unit.</td><td>*Twenty Cents*</td></tr>\n","<tr><td>`QUANTITY`</td><td>Measurements, as of weight or distance.</td><td>*Several kilometers, 55kg*</td></tr>\n","<tr><td>`ORDINAL`</td><td>\"first\", \"second\", etc.</td><td>*9th, Ninth*</td></tr>\n","<tr><td>`CARDINAL`</td><td>Numerals that do not fall under another type.</td><td>*2, Two, Fifty-two*</td></tr>\n","</table>\n","\n","source: https://notebook.community/rishuatgithub/MLPy/nlp/UPDATED_NLP_COURSE/02-Parts-of-Speech-Tagging/02-NER-Named-Entity-Recognition\n"]},{"cell_type":"markdown","metadata":{},"source":["Let's count the total number of DATE mentioned in the paper."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["import spacy\n","nlp = spacy.load(\"en_core_web_sm\")\n","# Process the texts\n","doc = nlp(alltexts)\n","len([ent for ent in doc.ents if ent.label_=='DATE'])"]},{"cell_type":"markdown","metadata":{},"source":["### Visualize the Named Entity\n","\n","We can use the entity visualizer to highlight the named entities and their labels in the given texts."]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Tesla\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," buys \n","<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    $1.5 billion\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n","</mark>\n"," in bitcoin, plans to accept it as payment.</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["import spacy\n","from spacy import displacy\n","\n","text = \"Tesla buys $1.5 billion in bitcoin, plans to accept it as payment.\"\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","doc = nlp(text)\n","# Visualize it by seeting style to be \"ent\" and jupyter to be True\n","displacy.render(doc, style=\"ent\", jupyter = True)"]},{"cell_type":"markdown","metadata":{},"source":["We can customize the entity visualizer by specifying the entities to mark and the colors to use for those entities using the options parameter. Let's look at the example of visualize the person with a specified color."]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary. [__init__.py:191]\n"]},{"data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">                   </div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["import spacy\n","from spacy import displacy\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","doc = nlp(alltexts)\n","# set person to mark and color to use\n","options = {\"ents\": ['PERSON'], \"colors\": {'PERSON':'#82E0AA'}}\n","## Visualize it by seeting style to be \"ent\" and jupyter to be True and the corresponding options\n","displacy.render(doc, style=\"ent\", jupyter = True, options=options)"]},{"cell_type":"markdown","metadata":{},"source":["# Summary\n","\n","\n","+ We can use PyPDF2 library to read pdf files.\n","+ We split the texts into tokens using nlp with a doc object.\n","+ We understand the lemmatization and can extract it from a doc object.\n","+ We learn how to remove the stop words from the given texts.\n","+ We can add or remove stop words from the Spacy stop words list.\n","+ We learn how to perform part of speech tagging. \n","+ We visualize the part of speech tagging.\n","+ We learn how to perform named entity recognization.\n","+ We visualize the named entities.\n","\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"nbformat":4,"nbformat_minor":4}
