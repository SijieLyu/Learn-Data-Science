{"cells":[{"cell_type":"markdown","source":["# Lesson 25 - Logistic Regression"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06f99689-d3fe-4a2d-b053-0f0be6c978f2"}}},{"cell_type":"code","source":["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, expr\n\nfrom pyspark.ml.feature import VectorAssembler, StringIndexer\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.classification import LogisticRegression \n\nspark = SparkSession.builder.getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1e688c4d-2845-4b8b-8cd2-e88e49ab995b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Sigmoid Function \n\nBefore discussion the logistic regression classification algorithm we need to introduce the **sigmoid function**. This function is defined according to the formula \\\\(\\sigma(z) = \\frac{1}{1 + e^{-z}}\\\\). A plot of the function is provided below. One of the most important properties of the sigmoid function is that it can accepts any real number as an input, but its output is always within the interval (0,1). This makes the sigmoid function useful in statistics and machine learning since its output can be interpreted as a probabilities. \n\n![Apache Spark](https://drbeane.github.io/files/images/417/sigmoid.png)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e51a21dd-fa33-4012-9e0d-db62b2caaeba"}}},{"cell_type":"markdown","source":["## Logistic Regression\n\n**Logistic regression** is classification algorithm that allows us to estimate the probability that a particular observation belongs to a particular class based on the value of some set of features for which we have measurements. A logistic regression model generates its probability estimates by first calculating a linear function of the feature values, and the then passing the result of that calculation to the sigmoid function to obtain a value between 0 and 1 that can be interpreted as a probability. \n\nTo explain this concept in more detail, suppose that we are working on a binary classification problem in which we wish to classify observations as belonging to one of two classes. For the sake of discussion, lets name the two classes positive and negative. Let \\\\(y\\\\)  be a variable that indicates the correct class for any given observation. We will set \\\\(y=0\\\\)   for observations in the negative class and \\\\(y=1\\\\)  for observations in the negative class. \n\nNow suppose that we have \\\\(K\\\\)  features that we plan to use in our model. We will represent the values of these features with variables \\\\(x_1, x_2, ..., x_K\\\\) . We will denote our model's estimate of the probability that a particular observation belongs to the positive class by \\\\(\\hat{p}_1\\\\).\n\nA logistic regression model is defined by a collection of coefficients \\\\(\\hat{\\beta}_0,\\hat{\\beta}_1,..., \\hat{\\beta}_K\\\\). Given these coefficients, the model generates its probability estimated \\\\(\\hat{p}_1\\\\) by first calculating a linear combination of the form \\\\( z = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 x_2 + ... + \\hat{\\beta}_K x_K\\\\). It then uses the sigmoid function to estimate the probability of the observation being in the positive class: \\\\(\\hat{p}_1 = \\sigma(z)\\\\). Once we have \\\\(\\hat{p}_1\\\\) we can then estimate the probality of the observation being in the negative class as follows: \\\\(\\hat{p}_0 = 1 - \\hat{p}_1\\\\).\n\nYou might be wondering where the coefficients \\\\(\\hat{\\beta}_0,\\hat{\\beta}_1,..., \\hat{\\beta}_K\\\\) come from. The short answer is that these are learned from the training data. The training algorithm is provided with several observations for which the true class is known and it finds the coefficients that result in the model that generates the best predictions for the training data. There is a lot of mathematics involved in finding these optimal coefficients, but fortunately the tools we will be using take care of this process for us."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b858b0a5-a7ae-4368-91fb-a531a2f360ac"}}},{"cell_type":"markdown","source":["## Load and Prepare Data\n\nIn this lesson, we will demonstrate how to use Spark to create, evaluate, and apply a logistic regression model to perform binary classification. For this example, we will be working with the Pima Diabetes dataset. The goal of this problem will be to use information collected from a medical screening to determine if a patient is likely to develop diabetes in the near future. The dataset consists of 768 observations of adults aged 21 or older. For each individual, we have values for 8 features, as well as a label named `Outcome` that indicates if the individual developed diabetes within 5 years of their data being collected. \n\nFurther information about this dataset can be found here: [Pima Diabetes Data](https://rdrr.io/cran/dprep/man/diabetes.html)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8dd3296e-0953-4bd4-afd0-6d4dc805139a"}}},{"cell_type":"code","source":[" pima_schema = (\n    'Pregnancies INTEGER, Glucose INTEGER, BloodPressure INTEGER, SkinThickness INTEGER, Insulin INTEGER, '\n    'BMI DOUBLE, DiabetesPedigreeFunction DOUBLE, Age INTEGER, Outcome STRING'\n)\n\npima = (\n    spark.read\n    .option('delimiter', ',')\n    .option('header', True)\n    .schema(pima_schema)\n    .csv('/FileStore/tables/pima_diabetes.csv')\n)\n\npima.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1b828742-6e9e-4441-81ad-03fa7ba88e77"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- Pregnancies: integer (nullable = true)\n |-- Glucose: integer (nullable = true)\n |-- BloodPressure: integer (nullable = true)\n |-- SkinThickness: integer (nullable = true)\n |-- Insulin: integer (nullable = true)\n |-- BMI: double (nullable = true)\n |-- DiabetesPedigreeFunction: double (nullable = true)\n |-- Age: integer (nullable = true)\n |-- Outcome: string (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Pregnancies: integer (nullable = true)\n-- Glucose: integer (nullable = true)\n-- BloodPressure: integer (nullable = true)\n-- SkinThickness: integer (nullable = true)\n-- Insulin: integer (nullable = true)\n-- BMI: double (nullable = true)\n-- DiabetesPedigreeFunction: double (nullable = true)\n-- Age: integer (nullable = true)\n-- Outcome: string (nullable = true)\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["pima.show(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6cad35b9-ebb9-45e2-986e-f1c7b78fd16d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+\n|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age| Outcome|\n+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+\n|          6|    148|           72|           35|      0|33.6|                   0.627| 50|Positive|\n|          1|     85|           66|           29|      0|26.6|                   0.351| 31|Negative|\n|          8|    183|           64|            0|      0|23.3|                   0.672| 32|Positive|\n|          1|     89|           66|           23|     94|28.1|                   0.167| 21|Negative|\n|          0|    137|           40|           35|    168|43.1|                   2.288| 33|Positive|\n|          5|    116|           74|            0|      0|25.6|                   0.201| 30|Negative|\n|          3|     78|           50|           32|     88|31.0|                   0.248| 26|Positive|\n|         10|    115|            0|            0|      0|35.3|                   0.134| 29|Negative|\n|          2|    197|           70|           45|    543|30.5|                   0.158| 53|Positive|\n|          8|    125|           96|            0|      0| 0.0|                   0.232| 54|Positive|\n+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+\nonly showing top 10 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+\nPregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age| Outcome|\n+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+\n          6|    148|           72|           35|      0|33.6|                   0.627| 50|Positive|\n          1|     85|           66|           29|      0|26.6|                   0.351| 31|Negative|\n          8|    183|           64|            0|      0|23.3|                   0.672| 32|Positive|\n          1|     89|           66|           23|     94|28.1|                   0.167| 21|Negative|\n          0|    137|           40|           35|    168|43.1|                   2.288| 33|Positive|\n          5|    116|           74|            0|      0|25.6|                   0.201| 30|Negative|\n          3|     78|           50|           32|     88|31.0|                   0.248| 26|Positive|\n         10|    115|            0|            0|      0|35.3|                   0.134| 29|Negative|\n          2|    197|           70|           45|    543|30.5|                   0.158| 53|Positive|\n          8|    125|           96|            0|      0| 0.0|                   0.232| 54|Positive|\n+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+\nonly showing top 10 rows\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["N = pima.count()\nprint(N)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"397b4b45-56d4-42d4-b804-46cf2678d4a6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">768\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">768\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Select Features\n\nWe will use the `columns` attribute of our DataFrame to create a list of names of the feature columns."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5226c0fb-c7eb-4f7b-9835-343f613c1f6a"}}},{"cell_type":"code","source":["features = pima.columns[:-1]\nprint(features)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6a05bbe9-92db-4d0d-ae6d-e3a3f5acd8bf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[&#39;Pregnancies&#39;, &#39;Glucose&#39;, &#39;BloodPressure&#39;, &#39;SkinThickness&#39;, &#39;Insulin&#39;, &#39;BMI&#39;, &#39;DiabetesPedigreeFunction&#39;, &#39;Age&#39;]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&#39;Pregnancies&#39;, &#39;Glucose&#39;, &#39;BloodPressure&#39;, &#39;SkinThickness&#39;, &#39;Insulin&#39;, &#39;BMI&#39;, &#39;DiabetesPedigreeFunction&#39;, &#39;Age&#39;]\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Distribution of Label Values\n\nTo serve as a baseline against which we can compare our model, we will check the distribution of the label values."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"15fa0b2f-58d0-454f-8150-4b38623cf7f4"}}},{"cell_type":"code","source":["(\n    pima\n    .select('Outcome')\n    .groupby('Outcome')\n    .agg(\n        expr('COUNT(*) as count'), \n        expr(f'ROUND(COUNT(*)/{N},4) as prop')\n    )\n    .show()\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d28fc120-949e-4cbc-978a-faa418db20b8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------+-----+-----+\n| Outcome|count| prop|\n+--------+-----+-----+\n|Positive|  268|0.349|\n|Negative|  500|0.651|\n+--------+-----+-----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-----+-----+\n Outcome|count| prop|\n+--------+-----+-----+\nPositive|  268|0.349|\nNegative|  500|0.651|\n+--------+-----+-----+\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Encode Target Variable\n\nTo train a classification model in Spark, it is required that our labels be numerical encoded. Currently, our label values are given by strings. We can use the `StringIndexer` class from `pyspark.ml.feature` to perform an integer encoding of the label. This is demonstrated in the cell below."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cbb7d3a5-978e-4f25-8773-23fcf839f89d"}}},{"cell_type":"code","source":["indexer = StringIndexer(inputCol='Outcome', outputCol='label').fit(pima)\npima = indexer.transform(pima)\npima.show(10)\n\n# The 1, 0 will be assigned sorted by frequency"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"67f4279f-2090-4d37-b577-1fd415b8bcb0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+-----+\n|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age| Outcome|label|\n+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+-----+\n|          6|    148|           72|           35|      0|33.6|                   0.627| 50|Positive|  1.0|\n|          1|     85|           66|           29|      0|26.6|                   0.351| 31|Negative|  0.0|\n|          8|    183|           64|            0|      0|23.3|                   0.672| 32|Positive|  1.0|\n|          1|     89|           66|           23|     94|28.1|                   0.167| 21|Negative|  0.0|\n|          0|    137|           40|           35|    168|43.1|                   2.288| 33|Positive|  1.0|\n|          5|    116|           74|            0|      0|25.6|                   0.201| 30|Negative|  0.0|\n|          3|     78|           50|           32|     88|31.0|                   0.248| 26|Positive|  1.0|\n|         10|    115|            0|            0|      0|35.3|                   0.134| 29|Negative|  0.0|\n|          2|    197|           70|           45|    543|30.5|                   0.158| 53|Positive|  1.0|\n|          8|    125|           96|            0|      0| 0.0|                   0.232| 54|Positive|  1.0|\n+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+-----+\nonly showing top 10 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+-----+\nPregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age| Outcome|label|\n+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+-----+\n          6|    148|           72|           35|      0|33.6|                   0.627| 50|Positive|  1.0|\n          1|     85|           66|           29|      0|26.6|                   0.351| 31|Negative|  0.0|\n          8|    183|           64|            0|      0|23.3|                   0.672| 32|Positive|  1.0|\n          1|     89|           66|           23|     94|28.1|                   0.167| 21|Negative|  0.0|\n          0|    137|           40|           35|    168|43.1|                   2.288| 33|Positive|  1.0|\n          5|    116|           74|            0|      0|25.6|                   0.201| 30|Negative|  0.0|\n          3|     78|           50|           32|     88|31.0|                   0.248| 26|Positive|  1.0|\n         10|    115|            0|            0|      0|35.3|                   0.134| 29|Negative|  0.0|\n          2|    197|           70|           45|    543|30.5|                   0.158| 53|Positive|  1.0|\n          8|    125|           96|            0|      0| 0.0|                   0.232| 54|Positive|  1.0|\n+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+-----+\nonly showing top 10 rows\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["print(type(indexer)) # the intexer itself is a string indexer object "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a162950a-b7c1-42cd-84d6-6a5e48c45888"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;class &#39;pyspark.ml.feature.StringIndexerModel&#39;&gt;\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &#39;pyspark.ml.feature.StringIndexerModel&#39;&gt;\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["print(indexer.labels)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c5c4c2a-b507-4a2e-a3a7-37aeae6bd81e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[&#39;Negative&#39;, &#39;Positive&#39;]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&#39;Negative&#39;, &#39;Positive&#39;]\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Assemble Feature Vector\n\nBefore we can use MLlib to create a machine learning model, we must first combine any columns representing features to be used in our model into a single column, which we will typically name `features`. Each entry in the `features` column will contain a list of feature values for that particular observation. In Spark terms, we will refer to this list as a feature vector. PySpark provides us with a `VectorAssembler` class that can be used to easily create this column."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cca5480a-e618-41e3-8ed9-b3861bd8fca0"}}},{"cell_type":"code","source":["assembler = VectorAssembler(inputCols=features, outputCol='features')\ntrain = assembler.transform(pima)\ntrain.show(5, truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9d247a78-df84-48e8-8cfb-12b694db9f73"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+-----+-------------------------------------------+\n|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin|BMI |DiabetesPedigreeFunction|Age|Outcome |label|features                                   |\n+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+-----+-------------------------------------------+\n|6          |148    |72           |35           |0      |33.6|0.627                   |50 |Positive|1.0  |[6.0,148.0,72.0,35.0,0.0,33.6,0.627,50.0]  |\n|1          |85     |66           |29           |0      |26.6|0.351                   |31 |Negative|0.0  |[1.0,85.0,66.0,29.0,0.0,26.6,0.351,31.0]   |\n|8          |183    |64           |0            |0      |23.3|0.672                   |32 |Positive|1.0  |[8.0,183.0,64.0,0.0,0.0,23.3,0.672,32.0]   |\n|1          |89     |66           |23           |94     |28.1|0.167                   |21 |Negative|0.0  |[1.0,89.0,66.0,23.0,94.0,28.1,0.167,21.0]  |\n|0          |137    |40           |35           |168    |43.1|2.288                   |33 |Positive|1.0  |[0.0,137.0,40.0,35.0,168.0,43.1,2.288,33.0]|\n+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+-----+-------------------------------------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+-----+-------------------------------------------+\nPregnancies|Glucose|BloodPressure|SkinThickness|Insulin|BMI |DiabetesPedigreeFunction|Age|Outcome |label|features                                   |\n+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+-----+-------------------------------------------+\n6          |148    |72           |35           |0      |33.6|0.627                   |50 |Positive|1.0  |[6.0,148.0,72.0,35.0,0.0,33.6,0.627,50.0]  |\n1          |85     |66           |29           |0      |26.6|0.351                   |31 |Negative|0.0  |[1.0,85.0,66.0,29.0,0.0,26.6,0.351,31.0]   |\n8          |183    |64           |0            |0      |23.3|0.672                   |32 |Positive|1.0  |[8.0,183.0,64.0,0.0,0.0,23.3,0.672,32.0]   |\n1          |89     |66           |23           |94     |28.1|0.167                   |21 |Negative|0.0  |[1.0,89.0,66.0,23.0,94.0,28.1,0.167,21.0]  |\n0          |137    |40           |35           |168    |43.1|2.288                   |33 |Positive|1.0  |[0.0,137.0,40.0,35.0,168.0,43.1,2.288,33.0]|\n+-----------+-------+-------------+-------------+-------+----+------------------------+---+--------+-----+-------------------------------------------+\nonly showing top 5 rows\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# The only two parts I use for the model\ntrain.select('label', 'features').show(5, truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"546b796c-46d1-4d9c-9114-9999e613990e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----+-------------------------------------------+\n|label|features                                   |\n+-----+-------------------------------------------+\n|1.0  |[6.0,148.0,72.0,35.0,0.0,33.6,0.627,50.0]  |\n|0.0  |[1.0,85.0,66.0,29.0,0.0,26.6,0.351,31.0]   |\n|1.0  |[8.0,183.0,64.0,0.0,0.0,23.3,0.672,32.0]   |\n|0.0  |[1.0,89.0,66.0,23.0,94.0,28.1,0.167,21.0]  |\n|1.0  |[0.0,137.0,40.0,35.0,168.0,43.1,2.288,33.0]|\n+-----+-------------------------------------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-------------------------------------------+\nlabel|features                                   |\n+-----+-------------------------------------------+\n1.0  |[6.0,148.0,72.0,35.0,0.0,33.6,0.627,50.0]  |\n0.0  |[1.0,85.0,66.0,29.0,0.0,26.6,0.351,31.0]   |\n1.0  |[8.0,183.0,64.0,0.0,0.0,23.3,0.672,32.0]   |\n0.0  |[1.0,89.0,66.0,23.0,94.0,28.1,0.167,21.0]  |\n1.0  |[0.0,137.0,40.0,35.0,168.0,43.1,2.288,33.0]|\n+-----+-------------------------------------------+\nonly showing top 5 rows\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Logistic Regression Model\n\nTo create a logistic regression model in Spark, we must first create an instance of the `LogisticRegression` class (which can be imported from `pyspark.ml.classification`). When creating this instance, we must provide values for the `featuresCol` and `labelCol` parameters. These should be set to the names of the columns containing our feature vector and label, respectively. The `LogisticRegression` object represents a training algorithm. \n\nTo create an actual model, we need to call the `fit()` method of our `LogisticRegression` object and pass it the DataFrame that contains our training data. The `fit()` method returns an object of type `LogisticRegressionModel`. This object will represent our model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03ea37cb-5c71-4486-a0d3-1cc97596bb6d"}}},{"cell_type":"code","source":["logreg = LogisticRegression(featuresCol='features', labelCol='label') # this line represents the algorithm\nlogreg_model = logreg.fit(train) # this line represents the model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3a35549-7299-4805-b9d9-2bddbfe83e23"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Model Coefficients\n\nThe coefficients defining our trained logistic regression model are contained in the `intercept` and `coefficients` attributes of our `LogisticRegressionModel` object. We will display these in the cell below."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04b8db23-7e9d-4d35-9c4e-87606021ee59"}}},{"cell_type":"code","source":["pd.DataFrame({\n    'Feature':['Intercept'] + features,\n    'Coefficient': [logreg_model.intercept] + logreg_model.coefficients.tolist()\n})             "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"73c00359-1bd9-4502-bb71-237bb3697023"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[27]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[27]: </div>"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Coefficient</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Intercept</td>\n      <td>-8.404703</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pregnancies</td>\n      <td>0.123183</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Glucose</td>\n      <td>0.035164</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BloodPressure</td>\n      <td>-0.013296</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SkinThickness</td>\n      <td>0.000619</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Insulin</td>\n      <td>-0.001192</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>BMI</td>\n      <td>0.089701</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>DiabetesPedigreeFunction</td>\n      <td>0.945183</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Age</td>\n      <td>0.014869</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Coefficient</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Intercept</td>\n      <td>-8.404703</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pregnancies</td>\n      <td>0.123183</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Glucose</td>\n      <td>0.035164</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BloodPressure</td>\n      <td>-0.013296</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SkinThickness</td>\n      <td>0.000619</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Insulin</td>\n      <td>-0.001192</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>BMI</td>\n      <td>0.089701</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>DiabetesPedigreeFunction</td>\n      <td>0.945183</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Age</td>\n      <td>0.014869</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Generating Predictions\n\nEvery object representing a trained machine learning model will come equipped with a `transform()` method that can be used to generated predictions. This method requires that a DataFrame be passed to it as an argument. This DataFrame must contain a `features` column containing vectors that have been assembled using the same `VectorAssembler` object that was trained on the training set. The method will return a DataFrame that contains all of the columns in the argument DataFrame as well as the following three new columns:\n\n* **`prediction`** - Each entry in this column will be a float representing a whole number value. This value indicates which of the label classes the model has predicted that the observation belongs to.\n* **`probability`** - Each entry in this column will be a vector with one element for each possible class for your target variable. The values contained in the vector will be the probabilities of the observation being in each of the possible classes, as estimated by the logistic regression model. This column is useful for assessing how confident the model is in its prediction, as well as for determining what other classes the model believes might be likely.\n* **`rawPrediction`** - Each entry in this column will be a vector with one element for each possible class for your target variable. The values contained in the vector will be the log odds scores that the model has assigned to each possible class. We will not make frequent use of this column."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ebc22bf-e117-41f3-ab9a-59c8a901f754"}}},{"cell_type":"code","source":["train_pred = logreg_model.transform(train)\ntrain_pred.select(['rawPrediction', 'probability', 'prediction', 'label']).show(10, truncate=False)\n\n# rawPrediction: [negate_z, z] ---> feed into sigmoid funciton to produce probability [prob_class0, prob_class1] "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1b778547-23dd-4849-8557-ea0851ae64bb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------------------------------------+-----------------------------------------+----------+-----+\n|rawPrediction                           |probability                              |prediction|label|\n+----------------------------------------+-----------------------------------------+----------+-----+\n|[-0.9530437928684456,0.9530437928684456]|[0.27827310282028067,0.7217268971797194] |1.0       |1.0  |\n|[2.9734135557588743,-2.9734135557588743]|[0.9513584846660905,0.04864151533390941] |0.0       |0.0  |\n|[-1.3658090650947372,1.3658090650947372]|[0.20329779895512906,0.7967022010448709] |1.0       |1.0  |\n|[3.136544880609751,-3.136544880609751]  |[0.9583752667606381,0.041624733239361875]|0.0       |0.0  |\n|[-2.2217341921957185,2.2217341921957185]|[0.0978156589529988,0.9021843410470012]  |1.0       |1.0  |\n|[1.761269957545264,-1.761269957545264]  |[0.8533686420756283,0.14663135792437154] |0.0       |0.0  |\n|[2.6404924640862077,-2.6404924640862077]|[0.9334225750752965,0.06657742492470349] |0.0       |1.0  |\n|[-0.5952553911853542,0.5952553911853542]|[0.35542993414178015,0.6445700658582199] |1.0       |0.0  |\n|[-0.892264330527107,0.892264330527107]  |[0.2906427702165224,0.7093572297834775]  |1.0       |1.0  |\n|[3.2779416989508983,-3.2779416989508983]|[0.9636642800607331,0.036335719939266854]|0.0       |1.0  |\n+----------------------------------------+-----------------------------------------+----------+-----+\nonly showing top 10 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------------+-----------------------------------------+----------+-----+\nrawPrediction                           |probability                              |prediction|label|\n+----------------------------------------+-----------------------------------------+----------+-----+\n[-0.9530437928684456,0.9530437928684456]|[0.27827310282028067,0.7217268971797194] |1.0       |1.0  |\n[2.9734135557588743,-2.9734135557588743]|[0.9513584846660905,0.04864151533390941] |0.0       |0.0  |\n[-1.3658090650947372,1.3658090650947372]|[0.20329779895512906,0.7967022010448709] |1.0       |1.0  |\n[3.136544880609751,-3.136544880609751]  |[0.9583752667606381,0.041624733239361875]|0.0       |0.0  |\n[-2.2217341921957185,2.2217341921957185]|[0.0978156589529988,0.9021843410470012]  |1.0       |1.0  |\n[1.761269957545264,-1.761269957545264]  |[0.8533686420756283,0.14663135792437154] |0.0       |0.0  |\n[2.6404924640862077,-2.6404924640862077]|[0.9334225750752965,0.06657742492470349] |0.0       |1.0  |\n[-0.5952553911853542,0.5952553911853542]|[0.35542993414178015,0.6445700658582199] |1.0       |0.0  |\n[-0.892264330527107,0.892264330527107]  |[0.2906427702165224,0.7093572297834775]  |1.0       |1.0  |\n[3.2779416989508983,-3.2779416989508983]|[0.9636642800607331,0.036335719939266854]|0.0       |1.0  |\n+----------------------------------------+-----------------------------------------+----------+-----+\nonly showing top 10 rows\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Scoring the Model\n\nThere are several metrics that can be used to score or evaluate a classification model. These metrics each have their advantages in certain situations, or when working with datasets with certain characteristics. The simplest (but not always best) classification metric is **accuracy**. A model's accuracy score with respect to a certain dataset is the proportion of observations for which the model predicts the correct class label. We can use the PySpark class `MulticlassClassificationEvaluator` to calculate a classification model's accuracy on a dataset. To use this tool, we must have created a dataset that contains predicted classes as well as the actual classes for the observations in the dataset. Such a DataFrame is returned by the `transform()` method of any MLlib model object. The syntax for using `MulticlassClassificationEvaluator` is shown below."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"adacc90c-94e8-4d6a-8dbb-82dec8cdbfcc"}}},{"cell_type":"code","source":["accuracy_eval = MulticlassClassificationEvaluator(\n    predictionCol='prediction', labelCol='label', metricName='accuracy')\n\nacc = accuracy_eval.evaluate(train_pred)\nprint(acc)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b8750d4a-86a3-42a6-8e70-4fc791504231"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">0.7825520833333334\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0.7825520833333334\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Generating Predictions for New Observations\n\nWe will now illustrate how to use our model to generate predictions for new observations. In the cell below, we create a DataFrame named `new_df` that is meant to contain feature values for two individuals to whom we would like to apply the model. In order to do so, we must first create features vectors for both observations. We can do this by using the `transform()` method of the `VectorAssembler` object we create earlier."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e29e6b8f-a1e8-47b7-a004-e3acab2bb3f7"}}},{"cell_type":"code","source":["new_df = spark.createDataFrame(\n    data = [[3, 130, 62, 33, 315, 31.5, 0.428, 37],\n            [5, 152, 71, 27, 254, 27.4, 0.638, 45]], \n    schema = (\n        'Pregnancies INTEGER, Glucose INTEGER, BloodPressure INTEGER, SkinThickness INTEGER,' \n        'Insulin INTEGER, BMI DOUBLE, DiabetesPedigreeFunction DOUBLE, Age INTEGER'\n    )\n)\n\nnew_df = assembler.transform(new_df)\nnew_df.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"420f69e5-1360-4ded-a1d5-912bae27ca26"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------------------------------------------+\n|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin|BMI |DiabetesPedigreeFunction|Age|features                                   |\n+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------------------------------------------+\n|3          |130    |62           |33           |315    |31.5|0.428                   |37 |[3.0,130.0,62.0,33.0,315.0,31.5,0.428,37.0]|\n|5          |152    |71           |27           |254    |27.4|0.638                   |45 |[5.0,152.0,71.0,27.0,254.0,27.4,0.638,45.0]|\n+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------------------------------------------+\nPregnancies|Glucose|BloodPressure|SkinThickness|Insulin|BMI |DiabetesPedigreeFunction|Age|features                                   |\n+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------------------------------------------+\n3          |130    |62           |33           |315    |31.5|0.428                   |37 |[3.0,130.0,62.0,33.0,315.0,31.5,0.428,37.0]|\n5          |152    |71           |27           |254    |27.4|0.638                   |45 |[5.0,152.0,71.0,27.0,254.0,27.4,0.638,45.0]|\n+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------------------------------------------+\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["new_pred = logreg_model.transform(new_df)\nnew_pred.select('probability', 'prediction').show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a2e23b56-d0f8-4073-b1ff-8d9f30786e3d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------------------------------------+----------+\n|probability                             |prediction|\n+----------------------------------------+----------+\n|[0.7032622044906212,0.29673779550937884]|0.0       |\n|[0.4859856114414946,0.5140143885585055] |1.0       |\n+----------------------------------------+----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------------+----------+\nprobability                             |prediction|\n+----------------------------------------+----------+\n[0.7032622044906212,0.29673779550937884]|0.0       |\n[0.4859856114414946,0.5140143885585055] |1.0       |\n+----------------------------------------+----------+\n\n</div>"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"25 - Logistic Regression","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2377394210003866}},"nbformat":4,"nbformat_minor":0}
