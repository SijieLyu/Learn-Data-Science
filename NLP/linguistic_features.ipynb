{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DSCI 614 Text Mining\n# Week 3: Linguistic Features\n\n","metadata":{}},{"cell_type":"markdown","source":"**Objectives**\n\n\nAfter you complete this module, students will be able to:\n\n+ Work with PDF files using PyPDF2\n+ Perform tokenization.\n+ Do lemmatization.\n+ Remove the stop words.\n+ Perform Part of Speech Tagging.\n+ Visualize the part of speech tags\n+ Do Named Entity Recondition.\n+ Visualize the name entity recognization\n\n\n\nWhen we perform text mining, we typically need to clean and preprocess the texts. Spacy provides common APIs to perform linguistic features\nbased on a Doc object. By the end of this week, I hope you'll understand the linguistic features. I will show you how to process PDF files using PyPDF2 library. Then we will cover the following list of text preprocessing steps: tokenization, lemmatization, part of speech tagging (POS), and named entity recognization (NER). Last but not least, we will learn how to visualize the POS tags and NERs. \n\n\n**Readings**\n\n+ Working with PDF files in Python (https://www.geeksforgeeks.org/working-with-pdf-files-in-python/)\n+ Tokenization (https://spacy.io/usage/linguistic-features#tokenization)\n+ Lemmatization (https://spacy.io/usage/linguistic-features#lemmatization)\n+ Part of Speech Tagging (https://spacy.io/usage/linguistic-features#pos-tagging)\n+ Named Entity Recondition (https://spacy.io/usage/linguistic-features#named-entities)\n\n","metadata":{}},{"cell_type":"markdown","source":"\n# Linguistic Features\n\nWe have learned how to clean and impute the numerical values. We have lots of tools to handle numerical features. But it is much harder for us to clean and preprocess the raw text features. Different words may mean the same thing; for example, STL, The Gateway City, and The Lou mean Saint Louis. On the other handle, sometimes the same word could mean different things. For example, there is an apple on the Apple Ipad. The apple has different meanings. \n\nSpacy provides the linguistic features to help us clean and preprocess the raw texts. We will cover the following topics this week:\n\n+ Tokenization\n+ Stemming\n+ Lemmatization\n+ Stop words\n+ Part of speech Tagging\n+ Named Entity Recognization\n","metadata":{}},{"cell_type":"markdown","source":"## Extract the Text from  PDF Files","metadata":{}},{"cell_type":"markdown","source":"Probably PDF is the most popular file format. These files can be accessed using a PC, Ipad, and smartphone on different operating systems such as Linux, macOS, and Windows. Therefore, we need a tool to handle PDF files using Python. There are many libraries to work with PDF files. We will use the PyPDF2 library (https://pypi.org/project/PyPDF2). It can perform the following tasks:\n\n+ extracting document information (title, author, …)\n+ splitting documents page by page\n+ merging documents page by page\n+ cropping pages\n+ merging multiple pages into a single page\n+ encrypting and decrypting PDF files\n\nThere are two methods to install PyPDF2.\n\n1. Install it with conda; we need to  run the following command: **conda install -c conda-forge pypdf2** in Anaconda Prompt.\n2. Install it with Jupyter Notebook; we need to run **pip install PyPDF2** in a cell.\n\nLet's install it in the Jupyter Notebook.","metadata":{}},{"cell_type":"code","source":"!pip install PyPDF2","metadata":{},"execution_count":1,"outputs":[{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: PyPDF2 in c:\\users\\liuyu\\anaconda3\\lib\\site-packages (1.26.0)\n"}]},{"cell_type":"markdown","source":"Let's load a paper titled \"Dollar-cost averaging just means taking risk later\" by Vanguard, into memory.","metadata":{}},{"cell_type":"code","source":"# Load the required library into memory\nimport PyPDF2\nimport re\n# Specify file\nmypdf = 'C:\\\\Users\\\\liuyu\\\\OneDrive\\\\OneDrive - Maryville University\\\\DSCI 614\\\\Modules\\\\WK3\\\\Dollar-cost_Averaging.pdf'\n# Creating a pdf file object\npdfFile = open(mypdf, 'rb')\n  \n# Creating a pdf reader object\npdfFileReader = PyPDF2.PdfFileReader(pdfFile)\n\n# Get the number of pages in the pdf file\npageCount = pdfFileReader.numPages\n# printing number of pages in pdf file\nprint(f' There are {pageCount} pages in the file :{mypdf}')\n  \noutput = []    \nfor i in range(pageCount):\n    # Get the i-th page contents from the pdf file\n    pdfPage = pdfFileReader.getPage(i)\n    # Extract text from each page and append it to the list\n    output.append(pdfPage.extractText())\n    \n# Concatenate items in the list to a single string\nalltexts = ' '.join(output)\n\n# Print out  the first 300 chars from the texts\nprint(\"----\" * 25)\nprint(alltexts[:300])\nprint(\"----\" * 25)  \n\n# Remove \\n from the texts\nalltexts = re.sub('\\n', '', alltexts)\n# Remove punctuation from the texts\nalltexts = re.sub(r'[^\\w\\s]','',alltexts)\n\n# Print out  the first 300 chars from the texts\nprint(\"----\" * 25)\nprint(alltexts[:300])\nprint(\"----\" * 25)  \n# closing the pdf file object\npdfFile.close()\n","metadata":{},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":" There are 8 pages in the file :C:\\Users\\liuyu\\OneDrive\\OneDrive - Maryville University\\DSCI 614\\Modules\\WK3\\Dollar-cost_Averaging.pdf\n----------------------------------------------------------------------------------------------------\nConnect with Vanguard \n > vanguard.com Executive summary. \nIf a foundation receives a $20 million cash gift, \n what are the tradeoffs to consider between investing those funds \nimmediately versus dollar-cost averaging the investment over time? \n How might an individual who receives a $1 million wind\n----------------------------------------------------------------------------------------------------\n----------------------------------------------------------------------------------------------------\nConnect with Vanguard   vanguardcom Executive summary If a foundation receives a 20 million cash gift  what are the tradeoffs to consider between investing those funds immediately versus dollarcost averaging the investment over time  How might an individual who receives a 1 million windfall approach\n----------------------------------------------------------------------------------------------------\n"}]},{"cell_type":"markdown","source":"## Tokenization\n\nWe notice that all the texts are stored in a single string object of alltexts. We want to split the entire pdf document into smaller segments, such as individual words called tokens.\n\nTo process texts in Spacy; we first need to generate a **Doc** object using nlp function.","metadata":{}},{"cell_type":"code","source":"import spacy\n# Load the model\nnlp = spacy.load(\"en_core_web_sm\")\n# Process the texts\ndoc = nlp(alltexts)\n# Print out the first 50 tokens\nfor token in doc[:50]:\n    print(f'Token text = {token.text}; Is the token lowercase? {token.is_lower}; Does the token consit of digits? {token.is_digit} ')","metadata":{},"execution_count":3,"outputs":[{"name":"stdout","output_type":"stream","text":"Token text = Connect; Is the token lowercase? False; Does the token consit of digits? False \nToken text = with; Is the token lowercase? True; Does the token consit of digits? False \nToken text = Vanguard; Is the token lowercase? False; Does the token consit of digits? False \nToken text =   ; Is the token lowercase? False; Does the token consit of digits? False \nToken text = vanguardcom; Is the token lowercase? True; Does the token consit of digits? False \nToken text = Executive; Is the token lowercase? False; Does the token consit of digits? False \nToken text = summary; Is the token lowercase? True; Does the token consit of digits? False \nToken text = If; Is the token lowercase? False; Does the token consit of digits? False \nToken text = a; Is the token lowercase? True; Does the token consit of digits? False \nToken text = foundation; Is the token lowercase? True; Does the token consit of digits? False \nToken text = receives; Is the token lowercase? True; Does the token consit of digits? False \nToken text = a; Is the token lowercase? True; Does the token consit of digits? False \nToken text = 20; Is the token lowercase? False; Does the token consit of digits? True \nToken text = million; Is the token lowercase? True; Does the token consit of digits? False \nToken text = cash; Is the token lowercase? True; Does the token consit of digits? False \nToken text = gift; Is the token lowercase? True; Does the token consit of digits? False \nToken text =  ; Is the token lowercase? False; Does the token consit of digits? False \nToken text = what; Is the token lowercase? True; Does the token consit of digits? False \nToken text = are; Is the token lowercase? True; Does the token consit of digits? False \nToken text = the; Is the token lowercase? True; Does the token consit of digits? False \nToken text = tradeoffs; Is the token lowercase? True; Does the token consit of digits? False \nToken text = to; Is the token lowercase? True; Does the token consit of digits? False \nToken text = consider; Is the token lowercase? True; Does the token consit of digits? False \nToken text = between; Is the token lowercase? True; Does the token consit of digits? False \nToken text = investing; Is the token lowercase? True; Does the token consit of digits? False \nToken text = those; Is the token lowercase? True; Does the token consit of digits? False \nToken text = funds; Is the token lowercase? True; Does the token consit of digits? False \nToken text = immediately; Is the token lowercase? True; Does the token consit of digits? False \nToken text = versus; Is the token lowercase? True; Does the token consit of digits? False \nToken text = dollarcost; Is the token lowercase? True; Does the token consit of digits? False \nToken text = averaging; Is the token lowercase? True; Does the token consit of digits? False \nToken text = the; Is the token lowercase? True; Does the token consit of digits? False \nToken text = investment; Is the token lowercase? True; Does the token consit of digits? False \nToken text = over; Is the token lowercase? True; Does the token consit of digits? False \nToken text = time; Is the token lowercase? True; Does the token consit of digits? False \nToken text =  ; Is the token lowercase? False; Does the token consit of digits? False \nToken text = How; Is the token lowercase? False; Does the token consit of digits? False \nToken text = might; Is the token lowercase? True; Does the token consit of digits? False \nToken text = an; Is the token lowercase? True; Does the token consit of digits? False \nToken text = individual; Is the token lowercase? True; Does the token consit of digits? False \nToken text = who; Is the token lowercase? True; Does the token consit of digits? False \nToken text = receives; Is the token lowercase? True; Does the token consit of digits? False \nToken text = a; Is the token lowercase? True; Does the token consit of digits? False \nToken text = 1; Is the token lowercase? False; Does the token consit of digits? True \nToken text = million; Is the token lowercase? True; Does the token consit of digits? False \nToken text = windfall; Is the token lowercase? True; Does the token consit of digits? False \nToken text = approach; Is the token lowercase? True; Does the token consit of digits? False \nToken text =  ; Is the token lowercase? False; Does the token consit of digits? False \nToken text = the; Is the token lowercase? True; Does the token consit of digits? False \nToken text = same; Is the token lowercase? True; Does the token consit of digits? False \n"}]},{"cell_type":"markdown","source":"Spacy token supports many attributes such as doc, sent, text, etc. Please see the official help documents for details. (https://spacy.io/api/token#attributes)","metadata":{}},{"cell_type":"markdown","source":"## Stemming and Lemmatization\n\nThe documents use different forms of a word/token such as go, went, going, etc. When we handle texts, there are typically lots of tokens. We like to reduce the derived words to their word stem, such as go for go, went, and going. According to Wikipedia (https://en.wikipedia.org/wiki/Stemming), \"The stem need not be identical to the morphological root of the word; it is usually sufficient that related words map to the same stem, even if this stem is not in itself a valid root.\" Spacy doesn't provide any function for stemming at all.\n\nLemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma .\n\nAccording to Wikipedia:\n\n\" Lemmatization is closely related to stemming. The difference is that a stemmer operates on a single word without knowledge of the context, and therefore cannot discriminate between words that have different meanings depending on the part of speech. However, stemmers are typically easier to implement and run faster. The reduced \"accuracy\" may not matter for some applications. In fact, when used within information retrieval systems, stemming improves query recall accuracy, or true positive rate, when compared to lemmatization. Nonetheless, stemming reduces precision, or the proportion of positively-labeled instances that are actually positive, for such systems.\n\nFor instance:\n\n+ The word \"better\" has \"good\" as its lemma. This link is missed by stemming, as it requires a dictionary look-up.\n+ The word \"walk\" is the base form for the word \"walking\", and hence this is matched in both stemming and lemmatization.\n+ The word \"meeting\" can be either the base form of a noun or a form of a verb (\"to meet\") depending on the context, e.g., \"in our last meeting\" or \"We are meeting again tomorrow\". Unlike stemming, lemmatization attempts to select the correct lemma depending on the context.\"\n\nSource: https://en.wikipedia.org/wiki/Lemmatisation","metadata":{}},{"cell_type":"code","source":"import spacy\n# Load the model\nnlp = spacy.load(\"en_core_web_sm\")\n# Process the texts\ndoc = nlp(alltexts)\n# Print out the first 50 tokens\nfor token in doc[:50]:\n    print(f'Token text = {token.text}; The lemma ={token.lemma_} ')","metadata":{},"execution_count":4,"outputs":[{"name":"stdout","output_type":"stream","text":"Token text = Connect; The lemma =connect \nToken text = with; The lemma =with \nToken text = Vanguard; The lemma =Vanguard \nToken text =   ; The lemma =   \nToken text = vanguardcom; The lemma =vanguardcom \nToken text = Executive; The lemma =Executive \nToken text = summary; The lemma =summary \nToken text = If; The lemma =if \nToken text = a; The lemma =a \nToken text = foundation; The lemma =foundation \nToken text = receives; The lemma =receive \nToken text = a; The lemma =a \nToken text = 20; The lemma =20 \nToken text = million; The lemma =million \nToken text = cash; The lemma =cash \nToken text = gift; The lemma =gift \nToken text =  ; The lemma =  \nToken text = what; The lemma =what \nToken text = are; The lemma =be \nToken text = the; The lemma =the \nToken text = tradeoffs; The lemma =tradeoff \nToken text = to; The lemma =to \nToken text = consider; The lemma =consider \nToken text = between; The lemma =between \nToken text = investing; The lemma =invest \nToken text = those; The lemma =those \nToken text = funds; The lemma =fund \nToken text = immediately; The lemma =immediately \nToken text = versus; The lemma =versus \nToken text = dollarcost; The lemma =dollarcost \nToken text = averaging; The lemma =average \nToken text = the; The lemma =the \nToken text = investment; The lemma =investment \nToken text = over; The lemma =over \nToken text = time; The lemma =time \nToken text =  ; The lemma =  \nToken text = How; The lemma =how \nToken text = might; The lemma =might \nToken text = an; The lemma =an \nToken text = individual; The lemma =individual \nToken text = who; The lemma =who \nToken text = receives; The lemma =receive \nToken text = a; The lemma =a \nToken text = 1; The lemma =1 \nToken text = million; The lemma =million \nToken text = windfall; The lemma =windfall \nToken text = approach; The lemma =approach \nToken text =  ; The lemma =  \nToken text = the; The lemma =the \nToken text = same; The lemma =same \n"}]},{"cell_type":"markdown","source":"## Stop Words\n\nWhen we speak English, the sentence may contain different words. For example, \"It is a beautiful day!\". However, there are five words in the previous sentence. There are only two keywords of \"beautiful day\". The other three words are the most common words in English. They contain little info. After we remove the stop words, we reduce the size of the tokens/words. It may help improve the performance of text mining.\n\n### Remove Stopwords\nWe can remove stopwords while performing the following tasks:\n\n+ Text Classification\n    + Spam Filtering\n    + Language Classification\n    + Genre Classification\n+ Caption Generation\n+ Auto-Tag Generation\n \n\n### Avoid Stopword Removal\n+ Machine Translation\n+ Language Modeling\n+ Text Summarization\n+ Question-Answering problems\n\nSource: https://www.analyticsvidhya.com/blog/2019/08/how-to-remove-stopwords-text-normalization-nltk-spacy-gensim-python/\n\n","metadata":{}},{"cell_type":"markdown","source":"Let's look at Spacy's default stop words","metadata":{}},{"cell_type":"code","source":"import spacy\n\nnlp = spacy.load('en_core_web_sm')\n\nspacy_stopwords = nlp.Defaults.stop_words\n\nprint(spacy_stopwords)\n","metadata":{},"execution_count":5,"outputs":[{"name":"stdout","output_type":"stream","text":"{'wherein', 'neither', 'yourself', 'without', 'because', 'whole', 'every', 'until', 'him', 'few', 'within', 'elsewhere', 'anywhere', 'otherwise', 'could', 'at', 'our', 'nobody', 'eight', 'the', '’s', 'after', 'see', 'thereafter', 'below', 'give', 'often', \"'re\", 'there', 'whom', 'thereby', 'amount', 'itself', 'nevertheless', 'everywhere', 'did', 'from', 'least', 'been', 'even', 'us', 'cannot', 'against', 'but', 'quite', 'top', 'too', 'show', 'we', 'her', 'an', \"'s\", 'together', 'each', 'something', 'except', 'five', 'forty', 'back', 'besides', 'noone', 'everything', 'himself', 'move', 'therefore', 'further', 'may', 'amongst', 'any', 'by', 'yourselves', 'whereby', \"'ll\", 'more', 'due', 'else', 'never', 'latter', 'around', 'now', 'toward', 'seem', 'whereupon', 'formerly', 'again', 'some', 'other', 'were', 'thru', 'latterly', 'very', 'will', 'what', 'through', 'either', '‘ll', 'i', 'a', 'such', 'already', \"'d\", 'was', 'upon', 'am', 'became', 'meanwhile', 'into', 'seeming', 'indeed', 'can', 'be', 'n’t', 'herein', 'next', 'towards', 'none', 'should', 'another', 'my', 'becoming', 'then', 'being', 'behind', 'these', 'as', 'whatever', 'yet', 'via', 'are', 'always', 'anyone', 'ever', 'onto', 'full', 'hereafter', 'with', 'whither', 'them', 'nine', 'still', 'throughout', 'whenever', 'part', 'becomes', 'ours', 'used', '‘m', 'seems', \"n't\", 'she', 'most', '’re', 'about', 'along', 'made', 'anyway', 'two', 'thence', 'fifteen', 'others', 'put', 're', 'also', 'therein', 'on', 'themselves', 'over', 'if', 'he', 'first', 'several', 'former', 'twelve', 'rather', \"'m\", 'before', 'n‘t', 'whoever', '’ll', 'call', 'anything', 'that', 'myself', 'his', 'name', 'nothing', 'thereupon', 'hereby', 'go', 'hence', 'ca', 'herself', 'enough', 'you', 'same', 'once', 'doing', 'various', 'above', 'own', 'much', 'many', 'whereas', 'they', 'anyhow', 'than', 'front', 'done', 'however', 'say', 'someone', 'hundred', 'six', 'sometimes', 'no', 'ourselves', 'here', 'which', 'take', 'using', 'serious', 'it', 'ten', 'beside', 'hers', 'eleven', 'somehow', 'its', 'twenty', 'have', 'those', 'nowhere', 'although', 'beforehand', 'well', 'or', 'had', 'between', 'when', 'where', 'since', 'off', 'afterwards', 'seemed', 'only', 'out', 'almost', 'among', 'up', 'all', 'across', 'regarding', 'sometime', 'side', '’m', 'in', 'both', 'three', 'everyone', 'mostly', 'fifty', 'empty', \"'ve\", 'become', 'thus', 'who', 'make', 'is', 'third', 'their', 'four', 'please', '‘d', 'really', 'and', 'alone', 'not', '‘ve', '’ve', 'per', 'mine', 'one', 'nor', 'for', 'hereupon', 'has', 'during', '’d', 'less', 'to', 'sixty', 'this', 'get', 'me', 'your', 'does', 'moreover', 'just', '‘s', 'do', 'while', 'unless', 'under', 'whether', 'namely', 'whence', 'somewhere', 'perhaps', 'might', 'down', 'why', 'must', 'bottom', 'how', 'whereafter', 'last', 'whose', 'keep', 'beyond', 'so', 'wherever', 'though', 'of', 'would', 'yours', '‘re'}\n"}]},{"cell_type":"markdown","source":"We remove all the default stop words from the texts.","metadata":{}},{"cell_type":"code","source":"\ndoc = nlp(alltexts)\n\ntokens_without_stopword= [token for token in doc if not token.text in spacy_stopwords]\n\n\nprint(tokens_without_stopword[:100])","metadata":{},"execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":"[Connect, Vanguard,   , vanguardcom, Executive, summary, If, foundation, receives, 20, million, cash, gift,  , tradeoffs, consider, investing, funds, immediately, versus, dollarcost, averaging, investment, time,  , How, individual, receives, 1, million, windfall, approach,  , decisionIn, paper, compare, historical, performance, dollarcost, averaging, DCA, lumpsum, investing, LSI, markets,  , United, States, United, Kingdom, Australia, On, average,  , nd, LSI, approach, outperformed, DCA, approach, approximately, twothirds, time, results, adjusted, higher, volatility, stockbond, portfolio, versus, cash, investments, This, nding,  , consistent, fact, returns, stocks, bonds, exceeded, cash, study, period, markets, We, conclude, investor, expects, trends, continue, satised, target, asset, allocation, comfortable,  , riskreturn, characteristics, strategy]\n"}]},{"cell_type":"markdown","source":"We notice that Vanguard appears many times in this report. It doesn't contain lots of information.  We may decide to remove it by adding it to the stop word list. \nSometimes, we may need to remove several words from the default stop words and keep them in the texts for a specific task. For example, \"call\" and \"put\" are included in the spacy's default stop words. This report covers investment strategies. It may involve put and call options. Therefore, we decide to keep them in the texts, remove \"call\", and \"put\" from Spacy's default stop words. ","metadata":{}},{"cell_type":"markdown","source":"### Add Customized Stop Words","metadata":{}},{"cell_type":"code","source":"print(f'There are {len(nlp.Defaults.stop_words)} stop words in Spacy')\n# Specify the user defined stop words\ncustomized_stop_words = ['Vanguard', 'market']\n# Add the user specified stop words to the Spacy default stop words\nfor token in customized_stop_words:\n    nlp.Defaults.stop_words.add(token)\n\n# Set the tag of the customized stop words as stop word \nfor token in customized_stop_words:\n    nlp.vocab[token].is_stop = True\nprint(f'There are {len(nlp.Defaults.stop_words)} stop words in Spacy')","metadata":{},"execution_count":7,"outputs":[{"name":"stdout","output_type":"stream","text":"There are 326 stop words in Spacy\nThere are 328 stop words in Spacy\n"}]},{"cell_type":"markdown","source":"### Remove Stop Words","metadata":{}},{"cell_type":"code","source":"print(f'There are {len(nlp.Defaults.stop_words)} stop words in Spacy')\n# Remove the the specified words from the default stop words of Spacy\nremove_stop_words = ['call', 'put']\n# Remove the user specified stop words from the Spacy default stop words\nfor token in remove_stop_words:\n    nlp.Defaults.stop_words.remove(token)\n\n# Set the tag of the removed stop words as non-stop word \nfor token in remove_stop_words:\n    nlp.vocab[token].is_stop = False\nprint(f'There are {len(nlp.Defaults.stop_words)} stop words in Spacy')","metadata":{},"execution_count":8,"outputs":[{"name":"stdout","output_type":"stream","text":"There are 328 stop words in Spacy\nThere are 326 stop words in Spacy\n"}]},{"cell_type":"markdown","source":"Let's clean the texts again based on the new defined stop words","metadata":{}},{"cell_type":"code","source":"doc = nlp(alltexts)\n\n# Get the new stop words\nspacy_stopwords = nlp.Defaults.stop_words\n\ntokens_without_stopword= [token for token in doc if not token.text in spacy_stopwords]\n\nprint(tokens_without_stopword[:250])","metadata":{},"execution_count":9,"outputs":[{"name":"stdout","output_type":"stream","text":"[Connect,   , vanguardcom, Executive, summary, If, foundation, receives, 20, million, cash, gift,  , tradeoffs, consider, investing, funds, immediately, versus, dollarcost, averaging, investment, time,  , How, individual, receives, 1, million, windfall, approach,  , decisionIn, paper, compare, historical, performance, dollarcost, averaging, DCA, lumpsum, investing, LSI, markets,  , United, States, United, Kingdom, Australia, On, average,  , nd, LSI, approach, outperformed, DCA, approach, approximately, twothirds, time, results, adjusted, higher, volatility, stockbond, portfolio, versus, cash, investments, This, nding,  , consistent, fact, returns, stocks, bonds, exceeded, cash, study, period, markets, We, conclude, investor, expects, trends, continue, satised, target, asset, allocation, comfortable,  , riskreturn, characteristics, strategy, prudent, action, research, July, 2012Dollarcost, averaging,  , means, taking, risk, laterAuthorsAnatoly, Shtekhman, CFAChristos, Tasopoulos, Brian, Wimmer, CFA, 2,  , investing, lump, sum, immediately, gain, exposure, markets,  , soon, possible, But, investor, primarily, concerned, minimizing, downside, risk, potential, feelings, regret, resulting, lumpsum, investing, immediately, downturn, DCA, use, Of, course, emotionally, based, concerns, weighed, carefully, 1, lower, expected, longrun, returns, cash, compared, stocks, bonds, 2, fact, delaying, investment, form, markettiming, investors, succeed, How, analysis, structuredOur, case, study, uses, monthly, stock, bond, returns, United, States, United, Kingdom, Australia, evaluate, historical, performance, strategy, For, LSI, assume, US1000000, 1000000, United, Kingdom, A1000000, Australia, immediately, invested, stockbond, portfolio, held, 10, years, For, DCA, assume, sum, starts, portfolio,  , cash, investments, transferred, equal, increments, stockbond, portfolio, period, 6, 12, 18, 24, 30, 36, months, 12, months, baseline, scenario, examples, exhibits, Once, DCA, investment, period, complete, DCA, LSI, portfolios, identical, asset, allocations, remain, invested, end, year, 10, We, compare]\n"}]},{"cell_type":"markdown","source":"## Part of Speech Tagging \n\nA Part-Of-Speech Tagging (POS Tagging) can read text  and assigns parts of speech to each word (and other token), such as noun, verb, adjective, etc.\n","metadata":{}},{"cell_type":"code","source":"import spacy\nnlp = spacy.load(\"en_core_web_sm\")\n# Process the texts\ndoc = nlp(alltexts)\n\n# Summarize the first 20 tokens\nfor token in doc[:20]:\n    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n            token.shape_, token.is_alpha, token.is_stop)","metadata":{},"execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":"Connect connect VERB VB ROOT Xxxxx True False\nwith with ADP IN prep xxxx True True\nVanguard Vanguard PROPN NNP pobj Xxxxx True False\n      SPACE _SP compound    False False\nvanguardcom vanguardcom NOUN NN dobj xxxx True False\nExecutive Executive PROPN NNP compound Xxxxx True False\nsummary summary NOUN NN npadvmod xxxx True False\nIf if SCONJ IN mark Xx True True\na a DET DT det x True True\nfoundation foundation NOUN NN nsubj xxxx True False\nreceives receive VERB VBZ advcl xxxx True False\na a DET DT det x True True\n20 20 NUM CD compound dd False False\nmillion million NUM CD nummod xxxx True False\ncash cash NOUN NN compound xxxx True False\ngift gift NOUN NN dobj xxxx True False\n    SPACE _SP dobj   False False\nwhat what PRON WP nsubj xxxx True True\nare be AUX VBP ccomp xxx True True\nthe the DET DT det xxx True True\n"}]},{"cell_type":"markdown","source":"### Visualize the Dependency Parser\n\nIt is well known that a graph is worth 1000 words. We can take advantage of the visualizer to show the dependency parser.","metadata":{}},{"cell_type":"code","source":"import spacy\nfrom spacy import displacy\n\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(\"Text mining is fun!\")\n# Visualize it by seeting style to be \"dep\" and jupyter to be True\ndisplacy.render(doc, style=\"dep\", jupyter = True)","metadata":{},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/html":"<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a4dc286f20f9472db9476f8b643ba1bc-0\" class=\"displacy\" width=\"750\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Text</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">mining</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">is</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">fun!</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n</text>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-a4dc286f20f9472db9476f8b643ba1bc-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-a4dc286f20f9472db9476f8b643ba1bc-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-a4dc286f20f9472db9476f8b643ba1bc-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-a4dc286f20f9472db9476f8b643ba1bc-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M245,91.5 L237,79.5 253,79.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-a4dc286f20f9472db9476f8b643ba1bc-0-2\" stroke-width=\"2px\" d=\"M420,89.5 C420,2.0 575.0,2.0 575.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-a4dc286f20f9472db9476f8b643ba1bc-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M575.0,91.5 L583.0,79.5 567.0,79.5\" fill=\"currentColor\"/>\n</g>\n</svg></span>","text/plain":"<IPython.core.display.HTML object>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Named Entity Recondition (NER)\nWhen we read the text, we naturally recognize named entities such as organizations, money, people, locations, etc. For example, in the news title\"Tesla buys $1.5 billion in bitcoin, plans to accept it as payment\", we can find the following named entities:\n\n+  **Tesla** is a company\n+  **\\$1.5billion** is the money\n\nIn information extraction, a named entity is a real-world object, such as persons, locations, organizations, products, etc., that can be denoted with a proper name. It can be abstract or have a physical existence. Examples of named entities include Barack Obama, New York City, Volkswagen Golf, or anything else that can be named. Named entities can simply be viewed as entity instances (e.g., New York City is an instance of a city).\n\nSource: https://en.wikipedia.org/wiki/Named_entity\n\n\nNamed entities are available as the ents property of a Doc object in Spacy.","metadata":{}},{"cell_type":"code","source":"import spacy\n\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(\"Tesla buys $1.5 billion in bitcoin, plans to accept it as payment\")\n\nfor ent in doc.ents:\n    print(ent.text, ent.start_char, ent.end_char, ent.label_)","metadata":{},"execution_count":12,"outputs":[{"name":"stdout","output_type":"stream","text":"Tesla 0 5 ORG\n$1.5 billion 11 23 MONEY\n"}]},{"cell_type":"markdown","source":"## NER Labels\nThe NER labels are summarized as follows:\n\n<table>\n<tr><th>TYPE</th><th>DESCRIPTION</th><th>EXAMPLE</th></tr>\n<tr><td>`PERSON`</td><td>People, including fictional.</td><td>*Fred Flintstone*</td></tr>\n<tr><td>`NORP`</td><td>Nationalities or religious or political groups.</td><td>*The Republican Party*</td></tr>\n<tr><td>`FAC`</td><td>Buildings, airports, highways, bridges, etc.</td><td>*Logan International Airport, The Golden Gate*</td></tr>\n<tr><td>`ORG`</td><td>Companies, agencies, institutions, etc.</td><td>*Microsoft, FBI, MIT*</td></tr>\n<tr><td>`GPE`</td><td>Countries, cities, states.</td><td>*France, UAR, Chicago, Idaho*</td></tr>\n<tr><td>`LOC`</td><td>Non-GPE locations, mountain ranges, bodies of water.</td><td>*Europe, Nile River, Midwest*</td></tr>\n<tr><td>`PRODUCT`</td><td>Objects, vehicles, foods, etc. (Not services.)</td><td>*Formula 1*</td></tr>\n<tr><td>`EVENT`</td><td>Named hurricanes, battles, wars, sports events, etc.</td><td>*Olympic Games*</td></tr>\n<tr><td>`WORK_OF_ART`</td><td>Titles of books, songs, etc.</td><td>*The Mona Lisa*</td></tr>\n<tr><td>`LAW`</td><td>Named documents made into laws.</td><td>*Roe v. Wade*</td></tr>\n<tr><td>`LANGUAGE`</td><td>Any named language.</td><td>*English*</td></tr>\n<tr><td>`DATE`</td><td>Absolute or relative dates or periods.</td><td>*20 July 1969*</td></tr>\n<tr><td>`TIME`</td><td>Times smaller than a day.</td><td>*Four hours*</td></tr>\n<tr><td>`PERCENT`</td><td>Percentage, including \"%\".</td><td>*Eighty percent*</td></tr>\n<tr><td>`MONEY`</td><td>Monetary values, including unit.</td><td>*Twenty Cents*</td></tr>\n<tr><td>`QUANTITY`</td><td>Measurements, as of weight or distance.</td><td>*Several kilometers, 55kg*</td></tr>\n<tr><td>`ORDINAL`</td><td>\"first\", \"second\", etc.</td><td>*9th, Ninth*</td></tr>\n<tr><td>`CARDINAL`</td><td>Numerals that do not fall under another type.</td><td>*2, Two, Fifty-two*</td></tr>\n</table>\n\nsource: https://notebook.community/rishuatgithub/MLPy/nlp/UPDATED_NLP_COURSE/02-Parts-of-Speech-Tagging/02-NER-Named-Entity-Recognition\n","metadata":{}},{"cell_type":"markdown","source":"Let's count the total number of DATE mentioned in the paper.","metadata":{}},{"cell_type":"code","source":"import spacy\nnlp = spacy.load(\"en_core_web_sm\")\n# Process the texts\ndoc = nlp(alltexts)\nlen([ent for ent in doc.ents if ent.label_=='DATE'])","metadata":{},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"61"},"metadata":{}}]},{"cell_type":"markdown","source":"### Visualize the Named Entity\n\nWe can use the entity visualizer to highlight the named entities and their labels in the given texts.","metadata":{}},{"cell_type":"code","source":"import spacy\nfrom spacy import displacy\n\ntext = \"Tesla buys $1.5 billion in bitcoin, plans to accept it as payment.\"\n\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(text)\n# Visualize it by seeting style to be \"ent\" and jupyter to be True\ndisplacy.render(doc, style=\"ent\", jupyter = True)","metadata":{},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/html":"<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Tesla\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n buys \n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    $1.5 billion\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n</mark>\n in bitcoin, plans to accept it as payment.</div></span>","text/plain":"<IPython.core.display.HTML object>"},"metadata":{}}]},{"cell_type":"markdown","source":"We can customize the entity visualizer by specifying the entities to mark and the colors to use for those entities using the options parameter. Let's look at the example of visualize the person with a specified color.","metadata":{}},{"cell_type":"code","source":"import spacy\nfrom spacy import displacy\n\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(alltexts)\n# set person to mark and color to use\noptions = {\"ents\": ['PERSON'], \"colors\": {'PERSON':'#82E0AA'}}\n## Visualize it by seeting style to be \"ent\" and jupyter to be True and the corresponding options\ndisplacy.render(doc, style=\"ent\", jupyter = True, options=options)","metadata":{},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/html":"<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Connect with Vanguard   vanguardcom Executive summary If a foundation receives a 20 million cash gift  what are the tradeoffs to consider between investing those funds immediately versus dollarcost averaging the investment over time  How might an individual who receives a 1 million windfall approach  the same decisionIn this paper we compare the historical performance of dollarcost averaging DCA with lumpsum investing LSI across three markets  the United States the United Kingdom and Australia On average we  nd that an LSI approach has outperformed a DCA approach approximately twothirds of the time even when results are adjusted for the higher volatility of a stockbond portfolio versus cash investments This nding  is consistent with the fact that the returns of stocks and bonds exceeded that of cash over our study period in each of these markets We conclude that if an investor expects such trends to continue is satised with his or her target asset allocation and is comfortable with  the riskreturn characteristics of each strategy the prudent action is Vanguard research July 2012Dollarcost averaging  just means taking risk laterAuthorsAnatoly Shtekhman CFAChristos \n<mark class=\"entity\" style=\"background: #82E0AA; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Tasopoulos Brian Wimmer\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n CFA 2  investing the lump sum immediately to gain exposure to the markets  as soon as possible But if the investor is primarily concerned with minimizing downside risk and potential feelings of regret resulting from lumpsum investing immediately before a market downturn then DCA may be of use Of course any emotionally based concerns should be weighed carefully against both 1 the lower expected longrun returns of cash compared with stocks and bonds and 2 the fact that delaying investment is itself a form of markettiming something few investors succeed at How the analysis is structuredOur case study uses monthly stock and bond returns in the United States United Kingdom and Australia to evaluate the historical performance of each strategy For LSI we assume that US1000000 or 1000000 in the United Kingdom and A1000000 in Australia is immediately invested into a stockbond portfolio and then held for 10 years For DCA we assume that the same sum starts in a portfolio  of cash investments and is then transferred in equal increments into a stockbond portfolio over a period of 6 12 18 24 30 or 36 months with 12 months being our baseline scenario in most examples and exhibits Once the DCA investment period is complete the DCA and LSI portfolios have identical asset allocations and both remain invested through the end of year 10 We then compare the ending portfolio values  from each strategy to determine how each performed during the 10year period We repeat  the comparison over rolling periods ie the first comparison for US markets covers the 10 years from January 1926 through December 1935 the second covers February 1926 through January 1936 and so on until we reach the 10 years through December 2011 We do the same for the relevant time periods in the United Kingdom and Australia In addition we repeat the analysis for various  stockbond allocations ranging from 100  equities to 100 bonds and for various holding periods ranging from 1 to 30 years Ultimately we calculate the probability and size of greater wealth accumulation in one strategy versus the other as well as the riskadjusted returns for each strategy during the initial DCA period See page 7 for more information about our methodology and a list of the benchmarks used in each marketNotes on risk All investments are subject to risk Past performance is no guarantee of future returns  The performance of an index is not an exact representation of any particular investment as you cannot invest directly in an index Dollarcost averaging does not guarantee that your investments will make a profit nor does it protect you against losses when stock or bond prices are falling There is no guarantee that any particular asset allocation or mix of funds will meet your investment objectives or provide you  with a given level of incomeExampleSource Vanguard020406080100120012345897610LSIDCADCAPeriodFully investedFully investedYears 3Summarizing the historical  outperformance of LSI versus DCAFigure 1 displays the historical probability of outperformance for LSI versus DCA when the  assets are invested into a 60 equity40 bond portfolio in the local market Despite the use of different international markets and time periods  our results are strikingly similar across the United States United Kingdom and Australia As we would expect LSI led to higher portfolio values in approximately twothirds of the periods analyzed since the average returns of stocks and bonds exceeded that of cash over the full span in each market These positive returns are responsible for the relative success of LSI over DCA This is really quite intuitiveŠif markets are going up its better to put your money to work right away to take full advantage of the market growth We found that any factors unrelated to market trends had a minimal impact on the results How the DCA period length affects  the resultsLSI outperformed DCA in a greater proportion of historical time periods regardless of the DCA period length As noted earlier in addition to the 12month DCA shown in Figure 1 we calculated outcomes  for 6 18 24 30 and 36month DCA investment periods again using the rolling 10year time frames in each market In general as the DCA period lengthened the probability of higher portfolio  values for LSI also increased In the United States for example LSI outperformed 36month DCA in approximately 90 of the 10year spansAs illustrated in Figure 2 on page 4 we found  that LSI portfolios tended to record higher returns than DCA portfolios even when the strategic asset allocations were either 100 equities or 100  fixed income Again this result is consistent with  the higher average returns of stocks and bonds  over cash instruments during our historical  sample periodFigure 1Relative historical probability of outperformance using 12month DCA and a 60 stock40 bond portfolioNote Each portfolio consists of a 60 allocation to the local equity market and a 40 allocation to the local bond market Source Vanguard calculations based on benchmark data See page 7 for a list of the benchmarks useda United States 1926Œ20110102030405060706733Lump sumDCAb United Kingdom 1976Œ20110102030405060706733Lump sumDCAc Australia 1984Œ20110102030405060706634Lump sumDCABased on rolling 10year periods in each market 4  Investors may also wonder whether the results would change if the overall holding period of the investment were to be shortened or lengthened  For instance how would the results change if the total holding period were 5 years or 20 years instead of 10 years Because our LSI and DCA portfolios have identical asset allocations at the end of the DCA period whichever portfolio has the most assets at that point will stay ahead forever However it is possible for the length of the holding period to affect the size of the gap between them The portfolio with the larger balance will have the potential for greater gains and losses over time even though the returns of both portfolios in percentage terms are identical On average by how much does LSI  outperform DCATo calculate the average magnitude of LSI outperformance we calculated the average ending values for a 6040 portfolio following rolling 10year investment periods In the United States 12month DCA led to an average ending portfolio value of 2395824 while LSI led to an average ending value of 2450264 or 23 more The results were similar in the United Kingdom and Australia UK investors would have ended with 22 more and Australian investors with 13 more on average DCA in the context of our research To some readers our research may seem to discount the benefits of dollarcost averaging  often cited in popular financial commentary  Such articles tend to recommend DCA largely  on the ground that investing a consistent dollar amount at regular intervals allows investors to diversify the prices they pay for a security buying more shares when prices are low and fewer  when prices are high This is true but there is a notable distinction between DCA as commonly discussed and as  a subject for the research covered in this paper Most popular commentary addresses DCA in terms of consistent investments made using current incomeŠie an employee transferring  a portion of each paycheck into a retirement account In that case investable cash becomes available only in relatively small amounts over time which makes DCA a prudent way to invest and really the only sound alternative to accumulating that money in cash and then actively trying to time the market at some later point Our research in contrast focuses on the strategies for investing an immediately available large sum  of money Here the average performance results have favored lumpsum investing Relative historical probability of outperformance for LSI versus 12month DCA at varying allocationsFigure 2 United States United Kingdom Australia  1926Œ2011 1976Œ2011 1984Œ2011 Lump sum DCA Lump sum DCA Lump sum DCA100 equity 66 34 68 32 62 3860 equity40 bonds 67 33 67 33 66 34100 bonds 65 35 61 39 58 42Source Vanguard calculations based on benchmark data See page 7 for a list of the benchmarks used 5It is important to reiterate that these are average returns Actual experience during any given period in the future may be much higher or lower depending on market trendsMeasuring the dispersion of outcomes  and riskadjusted performanceNow that we have demonstrated the stronger returns and therefore higher portfolio values generated by an LSI strategy it is important to look at its level of risk relative to DCA To do this we subtracted the ending portfolio values of an LSI strategy from the ending portfolio values of a 12month DCA strategy assuming 6040 ending allocations and 10year holding periods for both strategies We then ordered the results for each rolling 10year period by percentile rank Figure 3 summarizes the 5th 25th 50th 75th  and 95th percentiles of LSI performance relative to 12month DCA The 50thpercentile observation is positive confirming LSIs average outperformance but there is a fairly wide distribution of outcomes Obviously it is possible for either strategy to underperform the other over a given periodŠpotentially  by a significant amountNext we turn our focus to riskadjusted returns  An investor who implements a 12month DCA strategy is essentially decreasing the overall risk  of the portfolio via the higher allocation to cash during that period Does the degree of risk reduction achieved come at the expense of an even greater decline in potential returns To answer this question we measured the Sharpe ratios1 for one strategy versus the other across all possible 12month  DCA periods Despite its lower average ending portfolio values  a DCA strategy might be more favorable if the risk adjusted returns of a DCA portfolio during those first 12 months exceed the riskadjusted returns of an  LSI portfolio during that period However Figure 4 on page 6 shows that this is not the case LSI has provided better returns and riskadjusted returns  on averageRisk of loss and emotional considerationsEven though LSIs average outperformance and  riskadjusted returns have been greater than those  of DCA riskaverse investors may be less concerned about averages than they are about worstcase scenarios as well as the potential feelings of regret that would occur if a lumpsum investment were made immediately prior to a market decline These 1 The Sharpe ratio measures an investments excess returns per unit of risk and can be useful when comparing the performance of two portfolios with different asset allocationsDifferences between LSI and 12month DCA portfolio values after 10 yearsFigure 3The figures represent rankings of LSI balances subtracted from DCA balances At the 5thpercentile level for example 5 of the resulting amounts were lower than the amount listed and 95 were higher United States United Kingdom Australia  1926Œ2011 1976Œ2011 1984Œ20115th percentile ŒUS203776 Œ302385 ŒA22754325th percentile ŒUS42819 Œ36977 ŒA3732950th percentile US55151  64904 A42930 75th percentile US151725  174865 A136544 95th percentile US309133  441492 A281275Source Vanguard calculations based on benchmark data See page 7 for a list of the benchmarks used 6  concerns are not unreasonable We found that DCA performed better during market downturns so DCA may be a logical alternative for investors who prefer some shortterm downside protection Out of the 1021 rolling 12month investment  periods we analyzed for the US markets LSI investors would have seen their portfolios decline  in value during 229 periods 224 while DCA investors would have seen such declines during  only 180 periods 176 Furthermore the average loss during those 229 LSI periods was 84001 versus only 56947 in the 180 DCA periods The allocation to cash during the DCA investment period decreases the risk level of the portfolio helping to insulate it from a declining market It is essential to point out however that this temporarily cashheavy asset allocation is much more conservative than the investors true target allocation the one that will exist after the DCA period and that while this shortterm deviation  from the target provides some relative protection from market downturns it does so by sacrificing some potential for greater portfolio gains As with any asset allocation decision investors must determine for themselves whether or not reducing their portfolio risk in an attempt to avoid losses  and regrets is worth reducing the potential for  higher returnsConclusionClearly if markets are trending upward its logical  to implement a strategic asset allocation as soon as possible because it should offer a higher longrun expected return than cash Historically a longterm upward trend has persisted for both equities and bonds probably attributable to positive risk premia in the markets In other words positive returns have compensated investors for taking risks hence the upward trend in those markets and the resulting probabilities of success for LSI So to the extent that an investor believes the positive risk premia are likely to exist in the future LSI would remain the preferred method for investing an immediately available large sum of money But  if the investor is primarily concerned with reducing shortterm downside risk and the potential for regret then DCA may be a better alternative To be comfortable with either strategy an investor must be fully aware of the fact that historical averages are only a guideŠit is still possible for LSI or DCA to underperform or even lose money in any given period If an investor is uncomfortable with the risks associated with a given market entry strategy it may imply a low willingness to take risk in general and if so we recommend revisiting the target asset allocation to ensure that it appropriately addresses risk tolerance levels and investing goals Average annualized \n<mark class=\"entity\" style=\"background: #82E0AA; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Sharpe\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n ratios for LSI and 12month DCA portfolios measured over rolling  12month periods in each marketFigure 4 United States United Kingdom Australia  1926Œ2011 1976Œ2011 1984Œ2011 Lump sum DCA Lump sum DCA Lump sum DCA100 equity 077 068 063 060 052 04760 equity40 bonds 081 072 062 059 054 050100 bonds 080 072 036 033 034 029Note Sharpe ratios are calculated using local market returns and local rates on cash instrumentsSharpe ratio   nn1i1Var RpiŒRcashi1212RpiŒRcashiRcashi return of local cash rate for the ith monthRpi return of portfolio with a specic stockbond allocation for the ith monthSource Vanguard calculations based on benchmark data See page 7 for a list of the benchmarks used 7ReferencesBennyhoff Donald G 2009 Emotional Circuit Breakers Equity Implementation Plans Research Note Valley Forge Pa The Vanguard GroupConstantinides George M 1979 A Note on  the Suboptimality of DollarCost Averaging as  an Investment Policy Journal of Financial and Quantitative Analysis 14 June 443Œ50Gerstein Fisher  Associates 2011 Does Dollar  Cost Averaging Make Sense For Investors DCAs Benefits and \n<mark class=\"entity\" style=\"background: #82E0AA; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Drawbacks Examined\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n Available at gersteinfishercomresearchMalkiel Burton G 1973 latest rev 2003  A Random Walk Down Wall Street New York  WW Norton  CoRozeff \n<mark class=\"entity\" style=\"background: #82E0AA; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Michael S\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n 1994 LumpSum Investing Versus DollarAveraging Journal of Portfolio Management Winter 45Œ50Williams Richard E and \n<mark class=\"entity\" style=\"background: #82E0AA; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Peter W Bacon\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n 1993 Lump \n<mark class=\"entity\" style=\"background: #82E0AA; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Sum Beats\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n DollarCost Averaging Journal  of Financial Planning April 64Œ67A summary of our methodology and benchmarksInvestable assets to start US1000000 1000000 or A1000000LSI The LSI assets are fully invested immediately into a stockbond portfolio based on the local market Our study encompassed portfolio allocations ranging from 100 stocks to 100 bondsDCA The DCA assets including any interest earned from the cash portfolio are invested into the same allocation in equal monthly increments over a given period which we call the ﬁDCA periodﬂ DCA assets not yet invested are assumed to be held in cash instruments We studied outcomes for DCA periods of 6 12 18 24 30 and 36 monthsHolding period Both portfolios are held for  10 years We compared outcomes for rolling 10year periods over the full span of data available in each marketCalculations Both portfolios are rebalanced monthly to the target allocation Portfolio returns are based on monthly index data Transaction costs are not considered Market benchmarks used The study periods for each market were determined by the availability of reliable and consistent index data In each country we selected the indexes deemed to best represent the relevant market given the available choices  United States Equities Standard  Poors 90 January 1926ŒFebruary 1957 SP 500 Index March 1957ŒDecember 1974 Wilshire 5000  Index January 1975ŒApril 2005 MSCI US Broad Market Index May 2005ŒDecember 2011 Bonds SP High Grade Corporate Index January 1926ŒDecember 1968 Citigroup High Grade Index January 1969ŒDecember 1972 Lehman Brothers US Long Credit Aa Index January 1973Œ December 1975 Barclays Capital US Aggregate Bond Index January 1976ŒDecember 2011  Cash Ibbotson US 30Day Treasury Bill Index January 1926ŒDecember 1977 Citigroup  3Month US Treasury Bill Index January 1978ŒDecember 2011 United Kingdom Equities MSCI UK Total Return Index pounds February 1976ŒDecember 1985 FTSE All Share Total Return Index pounds  January 1986ŒDecember 2011 Bonds FTSE British Government Fixed All Total Return Index pounds February 1976ŒDecember 1998 Barclays Capital Sterling Hedged Index January 1999ŒDecember 2011 Cash Inferred from UK Interbank 1 MonthŒLIBOR February 1976ŒJanuary 1998 Citigroup World Money Market Index February 1998ŒDecember 2011 Australia Equities SPASX 300 Accumulation Index January 1984ŒDecember 2011 Bonds UBS Australian Composite Bond Index January 1984ŒDecember 2011 Cash Australian Dealer Bill 90 Day Total Return Index January 1984ŒAugust 1998 UBS Bank Bill Index September 1998ŒDecember 2011 Vanguard research  Vanguard Center for Retirement Research Vanguard Investment Counseling  Research Vanguard Investment Strategy GroupEmail  researchvanguardcomFor more information about Vanguard funds visit vanguardcom or call 8006622739 to obtain a prospectus Investment objectives risks charges expenses and other important information about a fund are contained in the prospectus read and consider it carefully before investingCFA is a trademark owned by CFA InstitutePO Box 2600 Valley Forge PA 194822600 2012 The Vanguard Group Inc All rights reserved  Vanguard Marketing Corporation Distributor ICRDCA072012      vanguardcomConnect with Vanguard</div></span>","text/plain":"<IPython.core.display.HTML object>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Summary\n\n\n+ We can use PyPDF2 library to read pdf files.\n+ We split the texts into tokens using nlp with a doc object.\n+ We understand the lemmatization and can extract it from a doc object.\n+ We learn how to remove the stop words from the given texts.\n+ We can add or remove stop words from the Spacy stop words list.\n+ We learn how to perform part of speech tagging. \n+ We visualize the part of speech tagging.\n+ We learn how to perform named entity recognization.\n+ We visualize the named entities.\n\n\n","metadata":{}}]}