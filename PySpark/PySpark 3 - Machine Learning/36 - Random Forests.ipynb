{"cells":[{"cell_type":"markdown","source":["# Lesson 36 - Random Forests"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06f99689-d3fe-4a2d-b053-0f0be6c978f2"}}},{"cell_type":"markdown","source":["## Prepare Environment"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9a3857ef-b9f4-44be-a479-d77e385009a5"}}},{"cell_type":"code","source":["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, expr\n\nfrom pyspark.ml.feature import VectorAssembler, OneHotEncoder, StringIndexer\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.classification import RandomForestClassifier, DecisionTreeClassifier\nfrom pyspark.mllib.evaluation import MulticlassMetrics\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\n\nspark = SparkSession.builder.getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1e688c4d-2845-4b8b-8cd2-e88e49ab995b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Random Forests\n\nAn **ensemble**  model is one that generates its predictions by combining the predictions from several simpler models. It is often the case that the ensemble model will have better predictive performance than any of the individual models from which it is built.\n\nA **random forest**  is an ensemble of many decision trees. To ensure that the trees are different from one another, each tree is trained on a different subset of the training set. Assume that our training set contains n observations. When building a tree model to be used in a random forest, a sample of size n is drawn from the training set, with replacement. Such a sample is referred to as a **bootstrap**  sample. We train each tree in the random forest on its own bootstrapped sample. Since each sample will likely be different from every other sample, this will encourage differences in the trees making up the random forest. \n\nWhen generating predictions with a random forest, the observations are provided to each of the individual trees, which will generate their own predictions. The final classifications generated by the forest are then obtained by allowing the trees to vote on the correct classification. \n\nEach of these trees in the forest will likely overfit to the training data, but in its own idiosyncratic way. When the predictions of the individuals are combined, these idiosyncrasies will likely get outvoted, and the forest will likely generate better predictions than the individual trees."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad5445bf-5960-4eaa-b329-2983266b1c91"}}},{"cell_type":"markdown","source":["## Load and Explore Data\n\nTo denomstrate the construction and application of random forests models in PySpark, we will use the [Diamonds dataset](https://ggplot2.tidyverse.org/reference/diamonds.html)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c23024bf-a1f3-405c-813e-13933f722db5"}}},{"cell_type":"code","source":["diamonds = (\n    spark.read\n    .option('delimiter', '\\t')\n    .option('header', True)\n    .schema(\n        'carat DOUBLE, cut STRING, color STRING, clarity STRING, depth DOUBLE, '\n        'table DOUBLE, price INTEGER, x DOUBLE, y DOUBLE, z DOUBLE'\n    )\n    .csv('/FileStore/tables/diamonds.txt')\n)\n\ndiamonds.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1b828742-6e9e-4441-81ad-03fa7ba88e77"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["diamonds.show(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6cad35b9-ebb9-45e2-986e-f1c7b78fd16d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["N = diamonds.count()\nprint(N)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"397b4b45-56d4-42d4-b804-46cf2678d4a6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["diamonds = diamonds.select('*', expr('LOG(carat) AS ln_carat'), expr('LOG(price) AS ln_price'))\ndiamonds.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cedd237b-0e19-457b-8920-0f5f18206b9e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Distribution of Label Values\n\nTo serve as a baseline against which we can compare our model, we will check the distribution of the label values."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"15fa0b2f-58d0-454f-8150-4b38623cf7f4"}}},{"cell_type":"code","source":["(\n    diamonds\n    .select('cut')\n    .groupby('cut')\n    .agg(\n        expr('COUNT(*) as count'), \n        expr(f'ROUND(COUNT(*)/{N},4) as prop')\n    )\n    .show()\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4acf8b20-4ade-40a3-bef9-6d0a7db2408e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Numerical and Categorical Features\n\nWe need to create lists specifying the names of our numerical features and our categorical features."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5226c0fb-c7eb-4f7b-9835-343f613c1f6a"}}},{"cell_type":"code","source":["num_features = ['ln_carat', 'ln_price', 'x', 'y', 'z', 'depth', 'table']\ncat_features = ['color', 'clarity']"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6a05bbe9-92db-4d0d-ae6d-e3a3f5acd8bf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Preprocessing Pipeline\n\nWe will now create stages to be used in a pre-processing pipeline. Since random forests are constructed from decision tress, which do not require one-hot encoding of categorical variables, we will simply need to perform an integer encoding of these variables."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"02285787-281d-4cc4-a118-ebe2bf1cebdb"}}},{"cell_type":"code","source":["ix_features = [c + '_ix' for c in cat_features]\n\nlabel_indexer = StringIndexer(inputCol='cut', outputCol='label')\n\nfeature_indexer = StringIndexer(inputCols=cat_features, outputCols=ix_features)\n\nassembler = VectorAssembler(inputCols=num_features + ix_features, outputCol='features')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a620e79d-9439-4e90-95f1-2a96eac6aacc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["preprocessor = Pipeline(stages=[label_indexer, feature_indexer, assembler]).fit(diamonds)\ntrain = preprocessor.transform(diamonds)\ntrain.persist()\ntrain.select(['features']).show(10, truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"45bd6fd8-d3ca-4419-a858-b9785a0f68c7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Evaluator\n\nWe will create an accuracy evaluator for use in scoring our models."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"64b492c3-7125-47ca-ad06-335dfec7a57a"}}},{"cell_type":"code","source":["accuracy_eval = MulticlassClassificationEvaluator(\n    predictionCol='prediction', labelCol='label', metricName='accuracy')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"71ef2b8e-dbfe-4716-a445-98b814926969"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Grid Seach for Random Forest\n\nAs with decision trees, we will typically want to use grid search to tune the hyperparameters `maxDepth` and `minInstancesPerNode`. You could also tune the `numTrees` hyperparameter, but this is not always practical. Since random forests consist of many tree models, they can be expensive to train and significantly more expensive to perform grid search with cross validation. As a result, unless we have a significant amount of computing resources available to us, we will need to pick a single value of `numTrees` to use. Generally speaking, higher values tend to produce better performance, but are much more time-consuming to train."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3cacbc06-8a40-4b20-b8b7-6f7dd661d3fc"}}},{"cell_type":"code","source":["rforest = RandomForestClassifier(featuresCol='features', labelCol='label', numTrees=20, seed=1)\n\nparam_grid = (ParamGridBuilder()\n              .addGrid(rforest.maxDepth, [14, 16, 18, 20, 22] )\n              .addGrid(rforest.minInstancesPerNode, [2, 4, 8, 16])\n              ).build()\n\ncv = CrossValidator(estimator=rforest, estimatorParamMaps=param_grid, numFolds=5, \n                    evaluator=accuracy_eval, seed=1, parallelism=6)\n\ncv_model = cv.fit(train)\n\nopt_model = cv_model.bestModel\nopt_maxDepth = opt_model.getMaxDepth()\nopt_minInstancesPerNode = opt_model.getMinInstancesPerNode()\n\nprint('Max CV Score:  ', round(max(cv_model.avgMetrics),4))\nprint('Optimal Depth:  ', opt_maxDepth)\nprint('Optimal MinInst:', opt_minInstancesPerNode)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c30a0760-6ff8-4c03-81f6-1be533cf49d9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["model_params = cv_model.getEstimatorParamMaps()\n\ndt_cv_summary_list = []\nfor param_set, acc in zip(model_params, cv_model.avgMetrics):\n    new_set = list(param_set.values()) + [acc]\n    dt_cv_summary_list.append(new_set)\n\ncv_summary = pd.DataFrame(dt_cv_summary_list, columns=['maxDepth', 'minInst', 'acc'])\n\nfor en in cv_summary.minInst.unique():\n    sel = cv_summary.minInst == en\n    plt.plot( cv_summary.maxDepth[sel]  , cv_summary.acc[sel], label=en)\n    plt.scatter(cv_summary.maxDepth[sel], cv_summary.acc[sel])  \nplt.legend()\nplt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c7b152d-0566-454d-a48c-d666d418787d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"36 - Random Forests","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2377394210004095}},"nbformat":4,"nbformat_minor":0}
